<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    
    <title>Python写一个简单的神经网络 | Jason&#39;s Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    
    <meta name="keywords" content="Machne Learning">
    <meta name="description" content="简单的神经网络算法，包括基本的后向传播BP算法，前向传播算法，更新权重使用的梯度下降算法，基本的框架算是有了，学习使用。注意输入每一行数据时候在神经网络中会加入bias偏量，神经网络的层数和每层个数为自定义，搞了很久才知道输入矩阵多了一个维度，权重和后向传播更新的delta都是每列神经元之间的关系，关于s形函数暂时用了两种，分别是logistic() 和 tanh() 效果差不多，简单的模型作为笔">
<meta name="keywords" content="Machne Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Python写一个简单的神经网络">
<meta property="og:url" content="http://sunlanchang.github.io/2017/10/21/测试文档/index.html">
<meta property="og:site_name" content="Jason&#39;s Blog">
<meta property="og:description" content="简单的神经网络算法，包括基本的后向传播BP算法，前向传播算法，更新权重使用的梯度下降算法，基本的框架算是有了，学习使用。注意输入每一行数据时候在神经网络中会加入bias偏量，神经网络的层数和每层个数为自定义，搞了很久才知道输入矩阵多了一个维度，权重和后向传播更新的delta都是每列神经元之间的关系，关于s形函数暂时用了两种，分别是logistic() 和 tanh() 效果差不多，简单的模型作为笔">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2017-10-22T11:31:44.440Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python写一个简单的神经网络">
<meta name="twitter:description" content="简单的神经网络算法，包括基本的后向传播BP算法，前向传播算法，更新权重使用的梯度下降算法，基本的框架算是有了，学习使用。注意输入每一行数据时候在神经网络中会加入bias偏量，神经网络的层数和每层个数为自定义，搞了很久才知道输入矩阵多了一个维度，权重和后向传播更新的delta都是每列神经元之间的关系，关于s形函数暂时用了两种，分别是logistic() 和 tanh() 效果差不多，简单的模型作为笔">
    
        <link rel="alternate" type="application/atom+xml" title="Jason&#39;s Blog" href="/atom.xml">
    
    <link rel="shortcut icon" href="/">
    <link rel="stylesheet" href="/css/style.css?v=1.6.16">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu"  >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">Jason Sun</h5>
          <a href="mailto:undefined" class="mail">
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Python写一个简单的神经网络</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="Search">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">Python写一个简单的神经网络</h1>
        <h5 class="subtitle">
            
                <time datetime="2017-10-20T16:43:50.000Z" itemprop="datePublished" class="page-time">
  2017-10-21
</time>


            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
<article id="post-测试文档"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">Python写一个简单的神经网络</h1>
        <div class="post-meta">
            <time class="post-time" title="2017-10-21 00:43:50" datetime="2017-10-20T16:43:50.000Z"  itemprop="datePublished">2017-10-21</time>

            


            

        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <p>简单的神经网络算法，包括基本的后向传播<code>BP</code>算法，前向传播算法，更新权重使用的梯度下降算法，基本的框架算是有了，学习使用。<br>注意输入每一行数据时候在神经网络中会加入<code>bias</code>偏量，神经网络的层数和每层个数为自定义，搞了很久才知道输入矩阵多了一个维度，权重和后向传播更新的delta都是每列神经元之间的关系，关于s形函数暂时用了两种，分别是<code>logistic()</code> 和 <code>tanh()</code> 效果差不多，简单的模型作为笔记学习使用。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">tanh</span><span class="params">(x)</span>:</span></div><div class="line">    <span class="keyword">return</span> np.tanh(x)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">tanh_deriv</span><span class="params">(x)</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="number">1.0</span> - np.tanh(x) * np.tanh(x)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">logistic</span><span class="params">(x)</span>:</span></div><div class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">logistic_derivative</span><span class="params">(x)</span>:</span></div><div class="line">    <span class="keyword">return</span> logistic(x) * (<span class="number">1</span> - logistic(x))</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuralNetwork</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, layers, activation=<span class="string">'tanh'</span>)</span>:</span></div><div class="line">        <span class="keyword">if</span> activation == <span class="string">'logistic'</span>:</div><div class="line">            self.activation = logistic</div><div class="line">            self.activation_deriv = logistic_derivative</div><div class="line">        <span class="keyword">elif</span> activation == <span class="string">'tanh'</span>:</div><div class="line">            self.activation = tanh</div><div class="line">            self.activation_deriv = tanh_deriv</div><div class="line"></div><div class="line">        self.weights = []</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(layers) - <span class="number">1</span>):</div><div class="line">            self.weights.append(</div><div class="line">                (<span class="number">2</span> * np.random.random((layers[i - <span class="number">1</span>] + <span class="number">1</span>, layers[i] + <span class="number">1</span>)) - <span class="number">1</span>) * <span class="number">0.25</span>)</div><div class="line">        self.weights.append(</div><div class="line">            (<span class="number">2</span> * np.random.random((layers[<span class="number">-2</span>] + <span class="number">1</span>, layers[<span class="number">-1</span>])) - <span class="number">1</span>) * <span class="number">0.25</span>)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y, learning_rate=<span class="number">0.2</span>, epochs=<span class="number">10000</span>)</span>:</span></div><div class="line">        X = np.atleast_2d(X)</div><div class="line">        temp = np.ones([X.shape[<span class="number">0</span>], X.shape[<span class="number">1</span>] + <span class="number">1</span>])</div><div class="line">        temp[:, <span class="number">0</span>:<span class="number">-1</span>] = X  <span class="comment"># adding the bias unit to the input layer</span></div><div class="line">        X = temp</div><div class="line">        y = np.array(y)</div><div class="line"></div><div class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(epochs):</div><div class="line">            i = np.random.randint(X.shape[<span class="number">0</span>])</div><div class="line">            a = [X[i]]</div><div class="line">            <span class="keyword">for</span> l <span class="keyword">in</span> range(len(self.weights)):  <span class="comment"># going forward network, for each layer</span></div><div class="line">                a.append(self.activation(np.dot(a[l], self.weights[l])))</div><div class="line">            error = y[i] - a[<span class="number">-1</span>]  <span class="comment"># Computer the error at the top layer</span></div><div class="line">            <span class="comment"># For output layer, Err calculation (delta is updated error)</span></div><div class="line">            deltas = [error * self.activation_deriv(a[<span class="number">-1</span>])]</div><div class="line">            <span class="comment"># Staring backprobagation</span></div><div class="line">            <span class="keyword">for</span> l <span class="keyword">in</span> range(len(a) - <span class="number">2</span>, <span class="number">0</span>, <span class="number">-1</span>):</div><div class="line">                deltas.append(deltas[<span class="number">-1</span>].dot(self.weights[l].T)</div><div class="line">                              * self.activation_deriv(a[l]))</div><div class="line">            deltas.reverse()</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.weights)):</div><div class="line">                layer = np.atleast_2d(a[i])</div><div class="line">                delta = np.atleast_2d(deltas[i])</div><div class="line">                self.weights[i] += learning_rate * layer.T.dot(delta)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, x)</span>:</span></div><div class="line">        x = np.array(x)</div><div class="line">        temp = np.ones(x.shape[<span class="number">0</span>] + <span class="number">1</span>)</div><div class="line">        temp[<span class="number">0</span>:<span class="number">-1</span>] = x</div><div class="line">        a = temp</div><div class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">0</span>, len(self.weights)):</div><div class="line">            a = self.activation(np.dot(a, self.weights[l]))</div><div class="line">        <span class="keyword">return</span> a</div><div class="line"></div><div class="line"></div><div class="line">nn = NeuralNetwork([<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>], <span class="string">'tanh'</span>)</div><div class="line">X = np.array([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]])</div><div class="line">y = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>])</div><div class="line">nn.fit(X, y)</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]]:</div><div class="line">    print(i, nn.predict(i))</div></pre></td></tr></table></figure></p>

        </div>

        <blockquote class="post-copyright">
    <div class="content">
        

        
    </div>
    <footer>
        <a href="http://sunlanchang.github.io">
            <img src="/" alt="Jason Sun">
            Jason Sun
        </a>
    </footer>
</blockquote>

        


        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machne-Learning/">Machne Learning</a></li></ul>


            


        </div>
    </div>

    


    











</article>



</div>

        <footer class="footer">
    <div class="top">
        

        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>This blog is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</span>
        </p>
    </div>
    <div class="bottom">
        <p><span>Jason Sun &copy; 2017</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>


    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: , REWARD: false };


</script>

<script src="/js/main.min.js?v=1.6.16"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.6.16" async></script>










</body>
</html>
