<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[2018全国高校大数据应用创新大赛]]></title>
    <url>%2F2018%2F06%2F24%2F2018%E5%85%A8%E5%9B%BD%E9%AB%98%E6%A0%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%94%E7%94%A8%E5%88%9B%E6%96%B0%E5%A4%A7%E8%B5%9B%2F</url>
    <content type="text"><![CDATA[描述 训练阶段：组委会提供25000条数据作为训练数据，参赛队伍报名后可从大赛官网下载训练数据集，并进行算法设计、训练和优化。 预赛阶段：组委会提供10万条数据作为预赛数据集。参赛队伍使用自己的算法，对这10万条数据进行“优化等级”标注。本竞赛将以优化等级标注的准确率作为选手预赛的得分。 分赛区决赛和全国总决赛阶段。组委会提供100万条正式比赛数据，参赛队伍使用自己的算法，对这100万条数据进行“优化等级”标注。本竞赛将以优化等级标注的准确率作为选手决赛的技术得分，结合决赛答辩评出最终名次。 详情见 http://117.50.29.62/pc/competition_topic.jsp 环境 环境 版本 Python模块 版本 Ubuntu 16.04 tensorflow 1.8 Anaconda 5.1 numpy Python 3.6 pandas Jupyter lab 0.31.5 matplotlib 数据预处理 标签列为数字特征，不做处理。 数据中特征列有花色，牌面等信息为字母标注，将其替换成数字特征，模型相对比较容易处理。比如C替换成1，D替换成2等。如下列代码所示： 12345NAMES = ['col'+str(e) for e in range(11)]df_train = pd.read_csv('data/train.csv',names=NAMES,index_col=False)huase_to_num = &#123;'C':1,'D':2,'H':3,'S':4&#125;paimian_to_num = &#123;'J':11,'Q':12,'K':13&#125;df_train=df_train.replace(huase_to_num).replace(paimian_to_num) 特征提取 前10列特阵列的数字特征 可以考虑使用交叉列输入神经网络 代码示例如下： 1234feature_columns = []for col in NAMES[:-1]: feature_columns.append(tf.feature_column.numeric_column(key=col))feature_columns 模型选择 神经网络采用三层隐藏层，神经元个数分别是1536,768,384 优化函数采用ProximalAdagradOptimizer 学习率0.005 L1正则化率0.001 L2正则化率0.001 具体代码如下：12345678910cls = tf.estimator.DNNClassifier( feature_columns=feature_columns, hidden_units=[1536,768,384], n_classes=numClasses, optimizer=tf.train.ProximalAdagradOptimizer( learning_rate=0.005, l1_regularization_strength=0.001, l2_regularization_strength=0.001 )) 模型训练与预测对已有的数据进行2000次训练，准确率如下图，20分钟训练模型2000次准确率99.5% 准确率 查看训练数据和预测数据分布 对数据进行预测并画出柱形图对比分布，如下图 训练数据分布 预测数据分布 大体可以看出分布是相同的]]></content>
  </entry>
  <entry>
    <title><![CDATA[拉勾网爬虫与数据分析]]></title>
    <url>%2F2018%2F06%2F02%2F%E6%8B%89%E5%8B%BE%E7%BD%91%E7%88%AC%E8%99%AB%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[拉勾网爬虫与数据挖掘描述爬取拉勾网50万条职位信息，进行数据清洗，简单的数据分析。流程图如下： 一个demo展示外观： 环境操作系统 Ubuntu 16.04 mac OS 10.13.3 数据获取 Chrome Python3 数据清洗 Excel DataGrip MySQL phpMyAdmin VScode Anaconda Jupyter Notebook 数据分析 Excel DataGrip MySQL phpMyAdmin Anaconda Jupyter Notebook 数据可视化 HTML Bootstrap JavaScript PHP Echarts Python模块 request BeautifulSoup Json numpy pandas matplotlib sklearn pymysql文件描述 get_position.py爬取拉勾网的爬虫程序 position_name.txt保存拉勾所有职位数据获取 使用Chrom分析拉勾源码，发现拉勾网使用Ajax请求数据如下图所示： 返回的数据是Json格式，处理起来非常方便，如下图所示： 需要的职位信息在object -&gt; content -&gt; positionResult -&gt; result 使用多线程策略在mac中，校园网环境下进行职位详情页的爬取，并采用BeautifulSoup4提取出网页中需要的文字信息，以便后期大数据分析。处理速度达到了每秒20个职位。 拉勾的反爬虫策略header不加session直接请求拉勾服务器，在请求数次之后就会被拒绝。手动注册账号登录拉勾网，利用Chrome开发工具将header的session后的字符串复制下载，加到程序的header中。这样再请求拉勾服务器就不会被拒绝了。注意超过一天之后session就失效了，登录账号更换一个新的session即可。 数据清洗去重(SQL)1234567891011CREATE TABLE tmp2 as select min(id) as mid from tab3 group by 职位IDCREATE TABLE lagou2 as SELECT * FROM lagou WHERE id in (SELECT mid from tmp2)``` ### 去重(Pandas)- 经过手工的查看有大量的重复值，使用`pandas`的`drop_duplicates(subset=['positionId'])`将重复的`positionId`去掉，只保留一行重复记录。- 用`pandas`的`pandas.DataFrame.to_csv()`将去重的文件保存为csv文件- Excel 2016打开去重的csv文件，利用快速填充提取字段的`4k-8k`等工资字段，取平均值。工作年限使用同样的操作提取- 创建MySQL数据库以导入csv文件，创建数据库如下,这里用的是`phpMyAdmin`手动创建数据库字段，自动生成创建语句：```sqlCREATE TABLE `LAGOU`.`position` ( `ID` INT NOT NULL AUTO_INCREMENT , `positionId` INT(10) NOT NULL , `positionLables` VARCHAR(20) NOT NULL , `positionName` VARCHAR(20) NOT NULL , `positionAdvantage` VARCHAR(20) NOT NULL , `firstType` VARCHAR(20) NOT NULL , `secondType` VARCHAR(20) NOT NULL , `workYear` INT(10) NOT NULL , `education` VARCHAR(20) NOT NULL , `salary` VARCHAR(20) NOT NULL , `isSchoolJob` VARCHAR(5) NOT NULL , `companyId` INT(10) NOT NULL , `companyShortName` VARCHAR(20) NOT NULL , `companyFullName` VARCHAR(20) NOT NULL , `companySize` VARCHAR(20) NOT NULL , `financeStage` VARCHAR(20) NOT NULL , `industryField` VARCHAR(20) NOT NULL , `industryLables` VARCHAR(20) NOT NULL , `createTime` VARCHAR(20) NOT NULL , `formatCreateTime` VARCHAR(20) NOT NULL , `city` VARCHAR(20) NOT NULL , `district` VARCHAR(20) NOT NULL , `businessZones` VARCHAR(20) NOT NULL , `linestaion` VARCHAR(20) NOT NULL , `stationname` VARCHAR(20) NOT NULL , PRIMARY KEY (`ID`)) ENGINE = InnoDB 其他 对文本数据进行数字编码，工作年限和工资等信息做统一的编码。 123456789ALTER TABLE L拉勾 ADD 工作年限 INT NULL;ALTER TABLE L拉勾 MODIFY COLUMN 工作年限 INT AFTER 工龄;UPDATE L拉勾 SET 工作年限 = 4 WHERE 工龄 = '3-5年';UPDATE L拉勾 SET 工作年限 = 2 WHERE 工龄 = '1-3年';UPDATE L拉勾 SET 工作年限 = 8 WHERE 工龄 = '5-10年';UPDATE L拉勾 SET 工作年限 = 10 WHERE 工龄 = '十年以上';UPDATE L拉勾 SET 工作年限 = 1 WHERE 工龄 = '一年以下';UPDATE L拉勾 SET 工作年限 = 0 WHERE 工龄 = '应届毕业生'; 数据分析利用MySQL进行简单的统计分析 招收人数最多的几个职位1SELECT 企业简称, COUNT(企业简称) as cnt FROM L拉勾 GROUP BY 企业简称 前100公司的招收人数1SELECT 企业简称,COUNT(企业简称) as cnt FROM L拉勾 GROUP BY 企业简称 ORDER BY cnt DESC LIMIT 100 月薪最高的100个职位1SELECT 职位名称,avg(工资) as money FROM L拉勾 GROUP BY 职位名称 ORDER BY money DESC LIMIT 100 学历水平工资1SELECT 学历,avg(工资) as money FROM L拉勾 GROUP BY 学历 ORDER BY money DESC 各个公司招收人的工薪水平1SELECT 企业简称,COUNT(企业简称) as cnt ,avg(工资) as money FROM L拉勾 GROUP BY 企业简称 ORDER BY cnt DESC,money DESC LIMIT 100 利用SKlearn进行数据分析数据预处理（中文分词、去除标点符号）先构建一个字典过滤标点符号，通过Python的jieba模块进行精确匹配模式进行分词后用空格分隔。示例如下：12345678910# encoding=utf-8chrs = ['，','。','！','、','；','：','？','~','(',')','；',';',',','\n','\t','/','-','.','\'']corpus = []for line in corpus_raw: for ch in chrs: line = line.replace(ch,'') Word_spilt_jieba = jieba.cut(line,cut_all = False) line = ' '.join(Word_spilt_jieba) corpus.append(line)print(corpus[0:3]) 对于职位的描述分词之后的（一个职位描述样本）如下所示，包含一些明确的关键词，同样也包含一些无关紧要的数字，在这里先不处理数字英文单词之类的（后续的预测准确率表明数字对结果影响不大）：1职位 要求 1 有 互联网 和 移动 互联网 行业 3 年 以上 产品 经理 从业 经验 2 独立 承担 项目 丰富 的 ERP 产品设计 经验 2 懂 app 基本 设计 流程 熟悉 微信 公众 号 的 后台 框架 及 运营 3 具备 项目 方案 起草 需求 整理 开发计划 及 相关 业务 对接 的 能力 4 有 很 强 的 产品 逻辑 与 项目 执行 能力 协调 沟通 部门 内外部 的 资源 5 具备 决策 和 项目 团队 管理 经验 特征选择词袋模型（ Bag-of-Words Model ） 使用机器学习算法时，我们不能直接使用文本。相反，我们需要将文本转换为数字。 对文档进行分类，每一类文档都是“输入”，而类别标签是我们预测算法的“输出”。算法将数字向量作为输入，因此我们需要将文档转换为固定长度的数字向量。 上面这一步可以通过为每个单词分配一个唯一的编码来完成。我们所看到的任何文档都可以被编码为一个固定长度的矢量，其长度为文档中全部已知单词的词汇量。矢量中每个位置的值可以用编码文档中每个单词的出现个数或频率填充。 在词袋模型中，我们只关心编码方案，而编码方案描述了文档中出现了什么单词，以及这些单词在编码文档中出现的频率，而没有任何关于顺序的信息。 对所有职位信息通过Python拉取数据库数据进行遍历，构建一个非常大的词袋，拉去50条职位描述信息时，构成的词袋长度就有2000条左右，这里局限于个人电脑和服务器的内存太小只用了小样本进行了构建词袋 使用 CountVectorizer 计算词频CountVectorizer 提供了一个简单的方法，既可以标记文本文档的集合, 也可以生成每个已知单词的索引, 还可以使用这一套索引对新文档进行编码。 下面是一种使用方法： 实例化一个 CountVectorizer 类。 调用 fit() 函数以从一个或多个文档中建立索引。 根据需要在一个或多个文档中调用 transform() 函数，将每个文档编码为一个向量。 123#该类会将文本中的词语转换为词频矩阵，矩阵元素a[i][j] 表示j词在i类文本下的词频 vectorizer=CountVectorizer() X = vectorizer.fit_transform(corpus) 转换后的结果可以看到X.shape为n*m，其中n为样本个数，m为特征个数，这里小样本词频测试输出如下（90%以上的都是0概率，可见是一个非常稀疏的矩阵）：1234567891011121314150.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.116133204036 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0924905834836 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0801139896408 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.230164048616 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0930653754409 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.106744931403 0.106744931403 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0922569939759 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.184513987952 0.0 0.0 0.0 0.0 0.0 0.0563738344688 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.117308212104 0.117308212104 0.117308212104 0.0 0.103965978559 0.0 0.117308212104 0.117308212104 0.0 0.117308212104 0.0 0.0 0.0 0.0 0.076084797887 0.0 0.0 0.0 0.0 0.0 ...... 稀疏矩阵由于大多数文本文档通常只使用文本词向量全集中的一个小子集，所以得到的矩阵将具有许多特征值为零（通常大于99％）。例如，10,000 个短文本文档（如电子邮件）的集合将使用总共100,000个独特词的大小的词汇，而每个文档将单独使用100到1000个独特的单词。为了能够将这样的矩阵存储在存储器中，并且还可以加速代数的矩阵/向量运算，实现通常将使用诸如 scipy.sparse 包中的稀疏实现。构造稀疏矩阵，对每一条记录分词之后 特征提取在一个大的文本语料库中，一些单词将出现很多次（例如 “the”, “a”, “is” 是英文），因此对文档的实际内容没有什么有意义的信息。 如果我们将直接计数数据直接提供给分类器，那么这些频繁词组会掩盖住那些我们关注但很少出现的词。为了为了重新计算特征权重，并将其转化为适合分类器使用的浮点值，因此使用 tf-idf 变换是非常常见的。 如何使用 TfidfVectorizer 将文本转换为词频向量。123#该类会统计每个词语的tf-idf权值 transformer=TfidfTransformer()tfidf=transformer.fit_transform(X) 这里降低不具有特征的词语例如’的‘，’是‘等。转换的矩阵仍然是一个非常稀疏的矩阵，例如这里的前20,职位描述和前20个特征词语概率如下：123456789101112130.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.116133204036 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0924905834836 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0801139896408 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.230164048616 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0930653754409 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.106744931403 0.106744931403 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0922569939759 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.184513987952 0.0 0.0 0.0 0.0 0.0 0.0563738344688 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 数据维度太大的解决思路使用 HashingVectorizer 执行外核缩放 使用 HashingVectorizer 的一个有趣的开发是执行外核 out-of-core 缩放的能力。 这意味着我们可以从无法放入电脑主内存的数据中进行学习。 项目等待完成的部分，也是可以优化计算的地方，在小样本测试算法成功后，可以使用此算法进行优化计算，以便在个人PC进行计算。 每批的向量化都是用HashingVectorizer这样来保证评估器的输入空间的维度是相等的。因此任何时间使用的内存数都限定在小频次的大小。 尽管用这种方法可以处理的数据没有限制，但是从实用角度学习时间受到想要在这个任务上花费的CPU时间的限制。 推荐职位 这里将推荐看做一个监督学习的分类问题，用户提供个人信息，利用训练完成的分类器对用户进行分类，将用户分类到某一个适合他的职位。具体实现思路是将用户的详情用训练的tf-idf转换器转换为一个稀疏矩阵，将稀疏矩阵输入分类器，分类器对其分类到某一个职位。 训练模型 利用Python动态拉取数据库的某一职位数据，对职位进行统一的编码，例如：[&#39;产品经理&#39;,&#39;前端开发工程师&#39;,&#39;测试工程师&#39;,&#39;平面设计师&#39;,&#39;UI设计师&#39;]将其编码为[1,2,3,4,5]，另一个实现是用One-Hot编码，两种实现均可，在这里发现第一种编码效果还是非常的不错。利用整个数据集训练时可以考虑使用One-Hot编码。 利用构造好的数据矩阵和标签矩阵进行训练，使用SVM模型（默认参数）123456789from sklearn import svm # 使用SVM模型clf = svm.SVC()clf.fit(weight,y)# SVM模型的参数SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False) 评测准确率 利用Python动态拉取MySQL数据的描述信息进行分词、构建稀疏矩阵、构造tf-idf稀疏矩阵、构造编码后标签矩阵输入模型对数据进行预测，并对照数据库的标签，对结果集进行验证准确率在90%以上，如下图对产品经理分类： 12# test_data为测试数据的稀疏矩阵clf.predict(test_data) 输出：12# 对20个产品经理小样本的预测分类准确率在100%array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]) 数据库查询 去重查询 1SELECT positionId,COUNT(DISTINCT positionId) FROM position GROUP by positionId 查询各个职位招收人数 1SELECT 职位名称,COUNT(职位名称) FROM L拉勾职位表 GROUP BY 职位名称 order BY COUNT(职位名称) desc 创建数据库1CREATE TABLE `LAGOU`.`position` ( `ID` INT NOT NULL AUTO_INCREMENT , `positionId` INT(10) NOT NULL , `positionLables` VARCHAR(20) NOT NULL , `positionName` VARCHAR(20) NOT NULL , `positionAdvantage` VARCHAR(20) NOT NULL , `firstType` VARCHAR(20) NOT NULL , `secondType` VARCHAR(20) NOT NULL , `workYear` INT(10) NOT NULL , `education` VARCHAR(20) NOT NULL , `salary` VARCHAR(20) NOT NULL , `isSchoolJob` VARCHAR(5) NOT NULL , `companyId` INT(10) NOT NULL , `companyShortName` VARCHAR(20) NOT NULL , `companyFullName` VARCHAR(20) NOT NULL , `companySize` VARCHAR(20) NOT NULL , `financeStage` VARCHAR(20) NOT NULL , `industryField` VARCHAR(20) NOT NULL , `industryLables` VARCHAR(20) NOT NULL , `createTime` VARCHAR(20) NOT NULL , `formatCreateTime` VARCHAR(20) NOT NULL , `city` VARCHAR(20) NOT NULL , `district` VARCHAR(20) NOT NULL , `businessZones` VARCHAR(20) NOT NULL , `linestaion` VARCHAR(20) NOT NULL , `stationname` VARCHAR(20) NOT NULL , PRIMARY KEY (`ID`)) ENGINE = InnoDB 导入导出数据库导出数据库 导出数据库为sql文件 12mysqldump -u root -p database_name table_name &gt; dump.txtpassword ***** 导出数据库为csv文件 12SELECT * FROM passwd INTO OUTFILE '/tmp/tutorials.txt' FIELDS TERMINATED BY ',' ENCLOSED BY '"'LINES TERMINATED BY '\r\n'; 导入数据库 csv文件导入数据库 1234load data local infile '/home/ubuntu//workspace/Lagou_Spider/lagou.txt'into table position_2fields terminated by ',' optionally enclosed by '"' escaped by '"'lines terminated by '\n'; 导入数据库sql文件1mysql -u root -p database_name &lt; dump.txt password ***** 其他常用命令和脚本 统计文件行数 1wc -l file tmux 1234tmux new -s sessiontmux new -s session -d #在后台建立会话tmux ls #列出会话tmux attach -t session #进入某个会话 合并文件 1234567import osfilenames = os.listdir("./position_id_files/")with open('all_describe_to_one.txt','a',encoding='utf-8') as f_write: for filename in filenames: with open('./position_id_files/'+filename,'r',encoding='utf-8') as f_read: for line in f_read.readlines(): f_write.write(line) 去重 1234import pandas as pddf = pd.read_csv(ready_to_read_file)df2=df.drop_duplicates(subset=['positionId'])df2.to_csv(ready_to_write_file) 参考 https://www.jianshu.com/p/16cd37a5355f&gt;https://www.zhihu.com/search?type=content&amp;q=%E6%8B%89%E5%8B%BE%20%E7%88%AC%E8%99%AB&gt;https://www.w3cschool.cn/mysql/mysql-database-export.htmlhttp://blog.csdn.net/liuxuejiang158blog/article/details/31360765http://blog.csdn.net/tiffany_li2015/article/details/50236833http://sklearn.apachecn.org/cn/0.19.0/modules/feature_extraction.htmlhttp://www.cnblogs.com/qcloud1001/p/8444576.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[北京邮电大学-数据挖掘竞赛-2018]]></title>
    <url>%2F2018%2F06%2F02%2F%E5%8C%97%E4%BA%AC%E9%82%AE%E7%94%B5%E5%A4%A7%E5%AD%A6-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%AB%9E%E8%B5%9B-2018%2F</url>
    <content type="text"><![CDATA[北京邮电大学-数据挖掘竞赛-2018description本次比赛是由北京邮电大学、北京师范大学、中国农业大学在2018年5月21到5月27日联合举办，提供了脱敏后真实校园数据用于大赛分析，本次比赛旨在推进智慧校园中大数据分析和应用。 本次比赛采用TensorFlow框架的High Level Api中DNN Regresor，利用GPU加速TensorFlow计算，快速迭代模型。大体的思路如下文所示，代码解析详情见：https://github.com/sunlanchang/bupt_bigdata_2018/blob/master/bigdata_with_tensorflow.ipynb 框架流程图 流程图 环境 环境 版本 Python模块 版本 Ubuntu 16.04 tensorflow 1.8 Anaconda 5.1 numpy Python 3.6 pandas Jupyter lab 0.31.5 matplotlib 数据预处理 合并1到10月所有csv文件 构造训练数据集 对每一个地点的用户ID总数统计，构造标签列。 合并文件利用pandas读取每个文件，将每个文件赋值给一个DataFrame，最后利用pd.concat()合并成为一个DaraFrame写入文件。 合并的文件如下图所示,共252014行： 地点 时间 人数 12 2017-11-28 12 11878 12 2017-11-20 12 11171 12 2017-11-23 12 10740 12 2017-11-21 12 10069 … … … 提取特征 提取已有的基本的特征 手工构造特征 提取特征列利用pandas对时间特征的解析，分离出日、月、小时等特征列， 特征列 building cat day hour is_weekend loc_id month weekday 特征列含义 建筑物编号 建筑物类别 日 小时 是否周末 地点ID 月 星期 选择模型采用sklearn和tensorflow模型多次训练模型，选择一个模型后优化模型。 其中tensorflow采用High Level APIs中的Estimator，快速开发迭代模型取得了较为不错的结果，并且可以灵活的改变神经网络的架构，不需要修改大量的代码。 Linear Regrassor 根据月份将数据可视化后（如下图所示），发现使用线性模型并不适合数据的拟合，训练模型后RMSE值为1000左右也印证了这个结论。 月份人数 SVM 使用sklearn.model_selection.train_test_split()划分数据集为训练数据集和验证数据集，使用sklearn.svm.SVC()训练模型。 经过累计20小时的训练和预测数据，结果不是很好，RMSE值为800左右。 利用sklearn的模型有明显的缺点，训练速度太慢，不能快速迭代模型是一个足够放弃这个框架的理由。 DNN Regrasor 采用支持cuda加速并且CPU并行计算的TensorFlow框架让模型迭代的速度有了明显的提升。训练batch_size大小为1千万，训练100次也不过用时不到一个小时。 经过实际测试隐藏层为4层[4096, 2048, 1024, 256]的神经网络在GPU训练速度是CPU的30倍左右。 DNN超参选择DNN架构方面尝试了多种不同的架构，利用Tensorboard查看收敛速度，得到一个相对较好的架构（如上所示） 受限于GPU显存只有4G，如果隐藏层神经元超过1万，显存溢出，程序无法执行。 如果神经网络层数设计的太长同样会出现这个问题。 只用三层隐藏层的DNN，隐藏层神经元设计成[2048,1024,512]，通过tensorboard发现，神经网络收敛的非常快，并且准确率和多一层的架构相差不超过5%。如下图所示： 其余超参例如激活函数，学习率，优化算法等采用tensorflow.estimator.DNNRegrasor()默认参数。1234567891011121314__init__( hidden_units, feature_columns, model_dir=None, label_dimension=1, weight_column=None, optimizer=&apos;Adagrad&apos;, activation_fn=tf.nn.relu, dropout=None, input_layer_partitioner=None, config=None, warm_start_from=None, loss_reduction=losses.Reduction.SUM) 模型训练 构建一个收入函数，对模型输入训练数据，训练数据有9/10做模型训练，1/10做模型的交叉验证，验证模型的准确率。 模型5000次迭代，20万条数据需要30分钟左右时间，根据tensorboard 查看收敛状态，调整神经网络架构。 tensorboard还有待调研，特别是数据的分布等图表可以很好的了解数据本身，从而从数据出发构建模型，调整模型。 模型评测 构建输入函数，对训练后的模型输入交叉验证数据，做模型准确率的验证。 利用1/10的数据做交叉验证，对比多个模型的准确率，收敛时间，确定模型在局部得到一个最优解。 模型预测 构建输入函数，输入模型等待预测的数据，运行一次模型，模型迭代输出等待预测的数据，可以保存的字典或列表中。 其他常用linux命令12tmux new-session -t $name 按照名字创建sessiontensorboard --logdir $your_path 开启tensorboard For more information https://tensorflow.google.cn/]]></content>
  </entry>
  <entry>
    <title><![CDATA[ACM八大输入输出格式之Python版]]></title>
    <url>%2F2018%2F01%2F21%2FACM%E5%85%AB%E5%A4%A7%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%A0%BC%E5%BC%8F%E4%B9%8BPython%E7%89%88%2F</url>
    <content type="text"><![CDATA[ACM八大输入输出格式之Python版12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697# encoding: utf-8#Python的输入是野生字符串，所以要自己转类型#strip去掉左右两端的空白符，返回str#slipt把字符串按空白符拆开，返回[str]#map把list里面的值映射到指定类型，返回[type]#EOF用抓异常#print后面加逗号就不会换行，否则反之，当然3.x君自行传参#题目细节没看太细，可能有的地方不对，不要在意这些细节啦# 有多组输入数据，但没有具体的告诉你有多少组，只是让你对应每组输入，应该怎样输出。while True: try: a, b = map(int, raw_input().strip().split()) print a + b, except EOFError: break # 输入一个整数，告诉我们接下来有多少组数据，然后在输入每组数据的具体值。tcase = int(raw_input().strip())for case in range(tcase): a, b = map(int, raw_input().strip().split()) print a + b, # 有多组输入数据，没有具体的告诉你有多少组,但是题目却告诉你遇见什么结束while True: a, b = map(int, raw_input().strip().split()) if a == 0 and b == 0: break print a + b, # 输入有多组，并却题目告诉你每组输入遇见什么结束，与第三种不同之处在于，每组输入都有相应的细化。 tcase = int(raw_input().strip())for case in range(tcase): a, b = map(int, raw_input().strip().split()) if a == 0 and b == 0: break print a + b, # 这次的输入实现输入一个整数，告诉我们有多少行，在输入每一行。对于每一行的输入，有划分为第一个数和其他的数，第一个数代表那一组数据一共有多少输入。tcase = int(raw_input().strip())for case in range(tcase): data = map(int, raw_input().strip().split()) n, array = data[0], data[1:] sum = 0 for i in range(n): sum += array[i] print sum, # 有多种输入数据，对于每组输入数据的第一个数代表该组数据接下来要输入数据量while True: try: data = map(int, raw_input().strip().split()) n, array = data[0], data[1:] sum = 0 for i in range(n): sum += array[i] print sum, except EOFError: raise # 这道题的输出只是简单的在每组输出后边多加一个换行而已！while True: try: a, b = map(int, raw_input().strip().split()) print a + b except EOFError: break # 这种类型的输出注意的就是换行，这类题目说在输出样例中，每组样例之间有什么什么，所以我们在对应输出的同时要判断一下是否是最后一组输出，如果不是，就 将题目所说的东西输出（一般是换行或空格），如果是，就直接结束。while True: data = raw_input().strip() if data.isspace(): break else: data = map(int, data) n, array = data[0], data[1:] sum = 0 for i in range(n): sum += array[i] print sum,]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>Other</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[传输层和应用层]]></title>
    <url>%2F2017%2F12%2F28%2F%E4%BC%A0%E8%BE%93%E5%B1%82%E5%92%8C%E5%BA%94%E7%94%A8%E5%B1%82%2F</url>
    <content type="text"><![CDATA[传输层端口号分配方法 占16位，地址范围0~65535，划分为3类： 熟知的端口号或系统端口号（0~1023）。 注册端口（1024~49151） 动态端口（49152~65535） UDP协议与TCP协议 UDP协议特点： 无连接的。发送数据前不需要建立连接，因此具有实时性。DNS、RIP等协议基于UDP协议。 面向报文的。不会对应用层产生的报文进行合并或分段处理，使得接收到的报文与发送的报文完全一致。 除了支持PPP（点对点通信）、还支持广播通信和多播通信。 报文格式：| 源端口 | 目的端口 | 总长度 | 校验和 | UDP数据部分 | TCP协议特点： 面向连接。通信前建立连接，通信完成后释放连接。 提供可靠服务。UDP协议是不可靠的。 只支持点对点的通信，而UDP支持点对点，多对多，例如按组实现的多人通话就是使用UDP协议。 全双工通信。双方可以同时收发数据。 面向字节流，将应用层下来的数据看成一连串的字节流。 报文格式有源端口、目的端口、序号、确认号、数据便宜标志位等 TCP协议的流量控制（与链路层类似）： TCP传输单位是报文，链路层传输单位是帧。 TCP采用滑动窗口机制，链路层流量控制的窗口大小固定。 TCP根据接收方的接收能力，通过接收窗口来实现端到端的流量控制，PPP链路层协议不使用确认机制和窗口机制。 TCP协议的拥塞控制4中算法 慢启动：指数增长 拥塞避免：线性方式增加。 快速重传和快速恢复：拥塞窗口重新设置为1，阈值减半。 应用层常见的应用层协议及其端口|服务进程|端口号|传输层协议|| – | – | – ||域名服务器|53|UDP||FTP数据|20|TCP||FTP控制|21|TCP||Telnet|23|TCP||SMTP|25|TCP||HTTP|80|TCP||POP|110|TCP| PPP与P2P区别：PPP(Point to Point Protocol),点对点协议它是一种协议。P2P（peer-to-peer),点对点，对等技术，他是一种技术。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络层]]></title>
    <url>%2F2017%2F12%2F28%2F%E7%BD%91%E7%BB%9C%E5%B1%82%2F</url>
    <content type="text"><![CDATA[网络层IP地址分类、子网划分、CIDR无分类编址IP地址分类方法 Note：IP数据报的分片:注意数据部分是8的整数倍。 RIP、OSPF路由选择协议RIP协议基本原理和特点原理：使用的距离向量算法要求每个路由器在路由表中列出到所有已知目的网络的最佳路由，并且定期把自己的路由表副本发送给与起直接连接的其他路由器。一条路径最多包含15个路由器，适用于小型互联网。基本特点 仅和自制系统内的相邻路由器交换信息。 支持两种信息交换方式，一种是定期的路由更新，另一种是触发的路由更新。 路由器交换的信息是自己现在的路由表。缺点 最大距离15。 网络规模的扩大，交换的路由表的开销将增加。 路由迅速发生变化，路由表可能来不及交换信息。 选择最短路由，但是速度不一定是最快的路由。 OSPF协议特点 使用分布式链路状态算法。 支持负载均衡，将距离、时延、带宽考虑进路由算法。 只有当链路状态发生变化时，才使用泛洪法向相邻的路由器发送信息更新路由表。 IPv6地址每个地址占128位，用冒号将每个十六位分隔开。有一下集中简写方法。 前导零压缩法：如ABCD:0:0:0:0:A2:0 零压缩法：如ABCD:::::A2:0 十六进制冒号与十进制点分法结合：如0:0:0:0:0:0:128.12.1.2 前缀长度表示法（与CIDR类似）：ABAA::AA:0:FFFF/60]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[物理层和数据链路层]]></title>
    <url>%2F2017%2F12%2F28%2F%E7%89%A9%E7%90%86%E5%B1%82%E5%92%8C%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82%2F</url>
    <content type="text"><![CDATA[物理层多路复用（Multiplexing）技术分类 频分多路复用（FDM）：通过不同的载波频率来划分若干个子信道，子信道之间互不干扰。 时分多路复用（TDM）：每一路信道只能在自己的时隙内独占信道传输。 波分多路复用（WDM）：与频分多路复用类似，他传输的是光信号，并按照光的波长区分信号。 码分多路复用（CDM）：每个用户使用经过特殊挑选的不同的码型通信，该技术有很强的抗干扰能力和安全性，广泛应用于移动通信和无线局域网中。 交换技术分类 线路交换：通过中间交换节点在两个站点之间建立一条专用的通信线路。 报文交换：将目的地址附到报文，网络节点根据报文上的地址信息，把报文发送到下一个节点，直到转送到目的节点。 分组交换：是报文交换的一种改进，分组的长度有一定的上限，提高了交换速度。包含虚电路分组交换和数据包分组交换。 数据编码技术包含模拟信号和数字信号两大类，主要讨论数字信号分类。 非归零码：低电平表示0，高电平表示1。 曼彻斯特编码：由低到高电平表示1（上跳），由高到低点评表示0（下跳）。 查分曼彻斯特编码：前半个码元电平与上一个码元的后半个码元的电平相同为1，相反为0。 时延种类及其计算时延包括发送时延、传播时延、处理时延。 总时延 = 发送时延 + 传播时延 + 处理时延 数据链路层组帧技术分类、特点,掌握组帧的具体应用方法 字节统计法：帧头部有一个域指定该帧中字节数。 字符填充法：使用标志字节FLAG来标志帧的开头与结尾，并且使用ESC来转义特殊字符。 零比特填充发：用一组特定的比特（0111110）赖标志帧的开始和结束。 奇偶校验码的方法和特点参见计算机组成原理的奇偶校验 CRC校验CRC的计算 滑动窗口技术、后退N帧ARQ协议和选择重传ARQ协议的工作原理 滑动窗口机制：网络中控制流量最常用的技术方案，发送发不必等待接收方的应答就可以连续发送数据帧，但对发送方在收到确认帧之前可以发送的数据帧的数目加以限制。 后退N帧ARQ协议：发送方可以连续发送多个数据帧而接收方只能按顺序接受指定序号的帧。 选择重传ARQ协议：接收方发现某帧出错后，将发送方正确的帧存放在缓冲区，要求发送方只重传出错的数据帧。 HDLC和PPP的特点HDLC基本特点 三种类型的站：1）主站负责控制链路操作。2）从站受控于主站。3）复合站具有主站和从站双重功能。 两种配置：1）平衡配置。2）非平衡配置 三种数据传送模式：1）正常相应模式。2）异步平衡模式。3）异步响应模式。 PPP（点对点协议） 没有确认机制和流量控制功能 只支持点对点线路和全双工链路]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络绪论和LAN（局域网）]]></title>
    <url>%2F2017%2F12%2F28%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%BB%AA%E8%AE%BA%E5%92%8CLAN%EF%BC%88%E5%B1%80%E5%9F%9F%E7%BD%91%EF%BC%89%2F</url>
    <content type="text"><![CDATA[绪论了解网络发展 面向终端的计算机网络 以通信子网为中心的计算机网络 体系结构标准化的网络 面向全球互连的计算机网络 网络拓扑结构分类 总线型结构 星型结构 环形结构 树形结构 网络协议 OSI 与 TCP/IP 的比较、协议各层的含义和基本传输单位 OSI和TCP/IP区别 物理层PhysicalLayer:原始比特流的传输(传输基本单位比特bit) 提供传输数据的物理通路 传输数据 主要设备:中继器、集线器 数据链路层DataLinkLayer:建立相邻节点数据链路传输 (传输基本单位帧frame) 数据链路的建立、维护、拆除、指定拓扑结构并提供硬件寻址 数据组帧 控制帧的收发顺序 差错检测与恢复.流量控制 主要设备:二层交换机、网桥 网络层Network layer :基于IP地址的路由选路传输数据 (传输基本单位数据包packet) 路由选路 拥塞控制、差错检测与恢复 网络互联 主要设备:路由器 传输层Transport layer: 常规数据传递,面向连接或者无连接 (传输基本单位数据段segment) 流量控制 会话层Session layer: 建立会话关系 表示层Presentation layer:统一数据传输格式 数据压缩和解压 数据加密和解密 应用层Application layer :为用户应用程序提供服务接口 LAN常见 LAN 的拓扑结构类型及其特点分析 星形网的特点： 网络结构简单，便于管理（集中式） 处理机负载重（需处理所有的服务） 入网主机故障不影响整个网络的正常工作，中心处理机的故障将导致网络的瘫痪。 总线网的特点： 多台机器共用一条传输信道，信道利用率较高 同一时刻只能由两台计算机通信 某个结点的故障不影响网络的工作 网络的延伸距离有限，结点数有限 环形网特点： 实时性较好（信息在网中传输的最大时间固定）； 每个结点只与相邻两个结点有物理链路 传输控制机制比较简单 某个结点的故障将导致物理瘫痪 单个环网的结点数有限 LAN的扩展方法及其特点 交换机、路由器和集线器三者的应用比较 集线器和交换机区别：集线器采用的式共享带宽的工作方式，而交换机是独享带宽。 路由器与集线器交换机区别：路由器作用在于连接不同的网段并且找到网络中数据传输最合适的路径。路由器与集线器交换机其他主要区别： 路由器工作在网络层，交换机和集线器工作在数据链路层和物理层。 路由器用IP地址转发数据，交换机利用MAC地址转发数据。 传统的交换机只能分割冲突域，不能分割广播域；而路由器可以分割广播域。 路由器可以提供防火墙功能。 VLAN 的实现技术 基于端口的VLAN 基于MAC地址的VLAN 基于第三层协议的VLAN 基于用户使用策略的VLAN CSMA/CD（载波监听多路访问/冲突检测）含义： 多路访问：许多计算机以多点接入的方式接入到总线网络。 载波监听：每个站在发送数据之前都要检测一下总线上是否有其它计算机在发送数据。 冲突检测：当几个站同时发送数据，总线上的信号电压摆动值将会增大（相互叠加）。发现冲突停止发送数据，等待一段随机时间再次发送。 原理：先听后发，边听边发，冲突停发，随机重发。 特点：在发送数据时，需要不断的检测信道是否有其他主机也在发送数据。 CSMA/CA（载波监听多路访问/冲突避免） 原理：利用ACk信号来避免冲突的发生，也就是说，只有当客户端收到网络上返回的ACK信号后，才确认送出的数据已经正确到达目的。 CSMA/CD与CSMA/CA区别： 前者用于总线式以太网，后者用于无线网路 检测信道空闲方式不同：前者通过检测电缆中电压的变化，后者利用能量检测（ED）、载波检测（CS）、能量载波混合检测 对于无线局域网（WLAN）中某个节点来说来说，信号会出现覆盖的情况 基于逆向学习算法,掌握透明网桥转发表的生成过程 透明指的是局域网上的站点并不知道所发送的帧经过那几个网桥，因为网桥对各站来说是看不见的。透明网桥是一种即插即用设备。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络部分题目]]></title>
    <url>%2F2017%2F12%2F27%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%83%A8%E5%88%86%E9%A2%98%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[简答题 TCP/IP和OSI模型比较，有哪些相同或不同之处？请分别给出两个方面。 解答：1）相同点：都是层次化模型；都有应用层、传输层、网络层。2）不同点：OSI模型分为7层具有网络协议理论指导价值，但未得到应用。TCP/IP模型分为4层得到了应用。 简要叙述虚拟局域网的划分技术。 解答：1）按交换机端口划分。2）按IP地址划分。3）按MAC地址划分。4）按用户策略划分 常见的局域网络扩展方法有哪几种？各有什么特点？ 解答：主要有三种。 采用集线器，工作于物理层，具有冲突域和广播域，每台主机的带宽减少，总带宽不变。 采用网桥或交换机，工作于数据链路层，具有广播域，隔离了冲突域，有广播风暴的风险。每台主机带宽不变，总带宽增加。 采用路由器，工作于网络层，隔离了广播域和冲突域，不会产生广播风暴，每台主机带宽不变，总带宽增加。 按发展历史，防火墙技术有哪四种类型？请说明每类型的特点 解答： 第一代防火墙：采用路由器，实现包过滤功能。 第二代防火墙：采用代理技术，提供网络服务级的控制，易于配置但速度较慢。 第三代防火墙：也叫状态监控功能的防火墙，可以对每一层数据进行检测和监控。 第四代防火墙：属于全方位的安全技术集成系统，采用安全内核、代理系统、多级过滤、安全服务器、鉴别和加密等关键技术。 计算题 考虑如图子网，有留个路由器。下面的矢量刚刚到达路由C：来自B的矢量为（5，0，8，12，6，2）（注：该矢量表示B到所有路由节点A，B，C，D，E，F的延迟分别为5，0，8，12，6，2一下同理）；来自D的矢量为（16,12,6,0,9,10）；来自E的矢量为（7,6,3,9,0,4）。经测量C到B、D和E的延迟分别为6、3、5。请使用距离矢量路由算法，按照下表格式，填写路由表C将要使用的输出线路以及期望的延迟。 路由图 节点号 延迟 输出线路 A B C 一IP数据包的数据部分为4800字节（使用固定首部），需要分片为长度不超过1500字节的分组。请按照一下内容，给出具体的分片设计结果。 解答：本题没有唯一答案，首要保证每一分片数据是8的整数倍，而且分片数量以最少为佳。如果最后一片未能达到要求，则可以由系统或用户补0直到满足要求。其中的一种分片可以是： 数据报片序号 数据长度 分组长度 原始数据报 4800 4820 数据报片1 1480 1500 数据报片2 1480 1500 数据报片3 1480 1500 数据报片4 360 380 请在下图中直接画出数据01011011001的非归零码、曼彻斯特编码和差分曼彻斯特编码三种编码方式的信号波形。 编码 在RSA密钥密码体制中，如果p=13,q=31,d=7,求c的值。给出具体求解过程。解答：$n=pq=1331=403$，$z=(p-1)(q-1)=1230=360$，$cd=1mod360$ ，已知$d=7$，可以求$c=103$。 设TCP的拥塞窗口的慢启动阈值为16（单位为报文段），当拥塞窗口上升到24时，网络发生超时，TCP开始慢启动和拥塞避免。要求：1）画出拥塞控制示意图，要求描述清晰，有明确的坐标信息。2）求第18次传输时拥塞窗口大小是多少？解答：1）当窗口为24时，实行拥塞控制避免，则新的阈值为24/2=12.拥塞控制示意图：1)12； 综合题 现在有一个公司需要创建企业网络，申请到的网络地址为198.97.6.0，该公司包括系统集成部、软件部、工程部和办公室4个部门，分别有28、21、14和8台计算机。为了便于开展工作，需要将这些部门划分子网管理。1）如何划分子网？给出具体过程和子网掩码。（子网号全0或全1不考虑）2）确定各个部门的网络地址，并写出分配给各个部门网络中的主机IP地址范围。解答：1）采用子网划分的方法对该公司的网络进行划分。由于该公司包括4个部门，共需要划分4个子网。已知网络地址198.97.6.0是一个C类地址各部门的主机最多为28/由于子网号和主机号不允许是全0或全1,因此子网号的比特数为3即最多有$2^3-2=6$，个可分配的子网，主机号的比特数为5即每个子网最多有$2^5-2=30$个可分配的IP地址，因此子网掩码为255.255.255.224。2）可用的6个子网的网络地址分别是：198.97.6.32、198.97.6.64、198.97.6.96、198.97.6.128、198.97.6.160、198.97.6.192，若选择前面4个，则有：子网198.97.6.32的主机IP范围为：198.97.6.33~198.97.6.62子网198.97.6.64的主机IP范围为：198.97.6.65~198.97.6.94子网198.97.6.96的主机IP范围为：198.97.6.97~198.97.6.126子网198.97.6.128的主机IP范围为：198.97.6.129~198.97.6.158]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[事务与并发控制、存储过程和触发器]]></title>
    <url>%2F2017%2F12%2F23%2F%E4%BA%8B%E5%8A%A1%E4%B8%8E%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E3%80%81%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E5%92%8C%E8%A7%A6%E5%8F%91%E5%99%A8%2F</url>
    <content type="text"><![CDATA[事务4个基本特征(ACID)： 原子性(atomicity)：事务是数据库的逻辑工作单位，事务中的操作要么都做，要么都不做。 一致性(consistency)：事务中的操作如果有一部分成功，一部分失败，为避免数据库产生不一致状态，系统会自动将事务中已完成的操作撤销，是数据库回到事务开始前的状态。因此事务的一致性和原子性是密切相关的。 隔离性(isolation)：一个事务的内部操作及使用的数据对其他事务是隔离的，并发执行的各个事务不能相互干扰。 持久性(durability)：事务一旦体骄傲，则其对数据库中的数据的改变就是永久的，以后的操作或故障不会对事务的操作结果擦好女生任何影响。 2种类型 隐式事务：每一条数据操作语句都是一个事务（例如一条select语句）。 显式事务:有显式的开始和结束标记的事务。 并发控制措施 共享锁（只允许读）：对于读操作来说，可以有多个事务同时获得一个数据的共享锁，但阻止其他事务对该数据进行排他锁。 排他锁（只允许读、写）：一旦一个事务获得对某一数据的排他锁，就不允许其他事务对该数据进行任何封锁。 存储过程创建和执行存储过程 例如：1234create proc pname @sname char(20)as select * from student where sname=@sname;]]></content>
      <categories>
        <category>数据库原理与应用</category>
      </categories>
      <tags>
        <tag>数据库原理与应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库概述和结构、数据模型、关系数据库]]></title>
    <url>%2F2017%2F12%2F22%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A6%82%E8%BF%B0%E5%92%8C%E7%BB%93%E6%9E%84%E3%80%81%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[数据库概览数据库系统本质是一个用计算机存储数据的系统，数据库是收集数据文件的仓库或容器，有永久存储、有组织和可共享的基本特点。数据库管理相对于文件管理的优点： 数据相互关联 较少的数据冗余 程序与数据相互独立 保证数据的安全可靠 最大限度保证数据的正确性 数据可以共享并能保证数据的一致性 数据模型数据模型及其分类 实体联系模型：涉及实体、属性、联系三方面（使用E-R图表示）。 层次数据模型：用树形结构表示实体和实体之间的联系（有父节点和子节点）。 网状数据模型：用图形结构表示实体和实体之间的联系（可以没有父节点）。 关系数据模型：用关系表示实体和实体之间的联系。 数据库模式结构：三级模式结构，由外向内是：外模式、模式、内模式 关系模型的组成关系数据结构：用二维表来组织数据，这个二维表在关系数据库中就称为关系。 关系操作 传统的关系运算：并、交、差、广义笛卡尔积 专门的关系运算：选择、投影、连接、除 有关的数据操作：查询、插入、删除、修改 实体完整性和参照完整性：系统级的约束，是必须满足的完整性约束。 用户自定义的完整性：应用级的约束，限制数据的取值范围等。 实体完整性：关系数据库中所有的表都必须有主码，而且表中不允许存在（1）无主码的记录（2）主码相同的记录 参照完整性：一个表中的关系的取值受到另一个表中关系的取值范围的约束（例如外码的选取）。 用户定义的完整性：一般是数据的取值范围的约束。 关系代数及其应用]]></content>
      <categories>
        <category>数据库原理与应用</category>
      </categories>
      <tags>
        <tag>数据库原理与应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关系数据库规范化理论]]></title>
    <url>%2F2017%2F12%2F18%2F%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A7%84%E8%8C%83%E5%8C%96%E7%90%86%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[基本概念函数依赖：如何构造一个合适的关系模式，应该构造几个关系模式，每个关系模式由哪些属性组成等，都是数据库的逻辑设计问题，其中各个属性之间的依赖关系就是函数依赖。例如：选课表中$(Sno, Cno) \rightarrow Grade$即成绩依赖与学生学号和课程号，或Sno和Cno决定Y。 设有关系模式R(A1,A2,…)，X和Y为R的一个子集，则： 如果$X \rightarrow Y$，但Y不包含于X，则称$X \rightarrow Y$是非平凡的函数依赖。 如果X不函数依赖与Y则记做$X \nrightarrow Y$。 如果$X \rightarrow Y$，则成为X为决定因子。 如果$X \rightarrow Y$并且$Y \rightarrow X$，则记做$X \leftrightarrow Y$。 如果$X \rightarrow Y$，并且对于X的每一个子集X1都有$X1 \nrightarrow Y$，则称Y完全依赖于X，若存在$X1 \rightarrow Y$反之为Y部分依赖于X。 如果$X \rightarrow Y$（即非平凡函数依赖$Y \nrightarrow X$）并且$Y \rightarrow Z$ ，则称Z传递依赖与X。 设U表示关系模式E的属性全集，F表示R上的函数依赖集，则关系模式R可表示为R(U, F) 候选码如果K为R中的属性或属性组，且K完全依赖于U，则K为R的候选码即K为决定R全部属性的最小属性组。 关系R(u, F)中可能有多个候选码，选其中一个作为主码。 全码：候选码为整个属性组。 主属性为包含在任一候选码中的属性，反之为非主属性。 用于建立关系表之间关联关系的属性称为外码。 范式第一范式不包含重复组属性（即不包含非原子项的属性）是第一范式的关系。第二范式如果R满足第一范式，并且R中每个非主属性都完全依赖于主码则R满足第二范式。（所有的属性都完全依赖主码，消除非主属性部的部分依赖） 例如：$SC(Sno, Cno, Sname, Grade)$中$(Sno, Cno)$是主码，而又有$Sno \rightarrow Sname$，因此$Sname$部分依赖于$(Sno, Cno)$。 模式分解： 用组成主码的属性集合的每一个子集作为主码构成一个关系模式。 将依赖于这些主码的属性放置到相应的关系模式中。 最后去掉只由主码的子集构成的关系模式。 第三范式R(U, F)满足第二范式，并且不存在传递依赖。 模式分解： 对于不是候选码的每个决定因子，总关系模式中删去依赖于它的所有属性。 新建一个关系模式，新关系模式中包含在原关系模式中所有依赖于该决定因子的属性。 将决定因子作为新关系模式的主码。 BC范式当且仅当关系中的每个函数依赖的决定因子都是候选码时，R满足BC范式。与第三范式区别：对于函数依赖$A \rightarrow B$，3NF允许B是主属性而A不是候选码，BCNF要求A必须是候选码。 关系模式的分解准则模式分解要满足： 模式分解具有无损连接性； 模式分解能够保持函数依赖。 无损连接是指分解后的关系通过自然连接可以恢复成原来的关系，即通过自然连接得到的关系与原来的关系相比，既不多出信息、又不丢失信息。 保持函数依赖分解是指在模式的分解过程中，函数依赖不能丢失的特性，即模式分解不能破坏原来的语义。]]></content>
      <categories>
        <category>数据库原理与应用</category>
      </categories>
      <tags>
        <tag>数据库原理与应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设置ssh私钥登录]]></title>
    <url>%2F2017%2F12%2F16%2F%E8%AE%BE%E7%BD%AEssh%E7%A7%81%E9%92%A5%E7%99%BB%E5%BD%95%2F</url>
    <content type="text"><![CDATA[安装sshsudo apt install ssh，若安装了，忽略这一步。 ssh配置主机A：10.0.5.199主机B：10.0.5.198需要配置主机A无密码登录主机B先确保所有主机的防火墙处于关闭状态，这里是开放22端口。在主机A上执行如下： 1. $cd ~/.ssh 2. $ssh-keygen -t rsa，然后一直按回车键，就会按照默认的选项将生成的密钥保存在.ssh/id_rsa文件中。 3. $cp id_rsa.pub authorized_keys 这步完成后，正常情况下就可以无密码登录本机了，即ssh localhost，无需输入密码。 4. $scp authorized_keys summer@10.0.5.198:/home/summer/.ssh，把刚刚产生的authorized_keys文件拷一份到主机B上. 5. $chmod 600 authorized_keys，进入主机B的.ssh目录，改变authorized_keys文件的许可权限。 Note：(4和5可以合成一步，执行: $ssh-copy-id -i summer@10.0.5.198) 参考 http://www.cnblogs.com/jdksummer/articles/2521550.html]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>Other</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP、TCP/IP协议、socket的区别]]></title>
    <url>%2F2017%2F12%2F15%2FHTTP%E3%80%81TCP-IP%E5%8D%8F%E8%AE%AE%E3%80%81socket%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[在配置Shadowsocks客户端遇到了Socket接口的问题，特地查阅了一下TCP/IP协议层的Socket，总的来说它是TCP/IP的一个抽象的接口。 TCP/IP连接手机能够使用联网功能是因为手机底层实现了TCP/IP协议，可以使手机终端通过无线网络建立TCP连接。TCP协议可以对上层网络提供接口，使上层网络数据的传输建立在“无差别”的网络之上。建立起一个TCP连接需要经过“三次握手”： 第一次握手：客户端发送syn包(syn=j)到服务器，并进入SYN_SEND状态，等待服务器确认； 第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态； 第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=k+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。握手过程中传送的包里不包含数据，三次握手完毕后，客户端与服务器才正式开始传送数据。理想状态下，TCP连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP 连接都将被一直保持下去。断开连接时服务器和客户端均可以主动发起断开TCP连接的请求，断开过程需要经过“四次握手”（过程就不细写了，就是服务器和客户端交互，最终确定断开。HTTP连接HTTP协议即超文本传送协议(Hypertext Transfer Protocol )，是Web联网的基础，也是手机联网常用的协议之一。HTTP协议是建立在TCP协议之上的一种应用。HTTP连接最显著的特点是客户端发送的每次请求都需要服务器回送响应，在请求结束后，会主动释放连接。从建立连接到关闭连接的过程称为“一次连接”。 在HTTP 1.0中，客户端的每次请求都要求建立一次单独的连接，在处理完本次请求后，就自动释放连接。 在HTTP 1.1中则可以在一次连接中处理多个请求，并且多个请求可以重叠进行，不需要等待一个请求结束后再发送下一个请求。由于HTTP在每次请求结束后都会主动释放连接，因此HTTP连接是一种“短连接”，要保持客户端程序的在线状态，需要不断地向服务器发起连接请求。通常的做法是即时不需要获得任何数据，客户端也保持每隔一段固定的时间向服务器发送一次“保持连接”的请求，服务器在收到该请求后对客户端进行回复，表明知道客户端“在线”。若服务器长时间无法收到客户端的请求，则认为客户端“下线”，若客户端长时间无法收到服务器的回复，则认为网络已经断开。SOCKET原理套接字（socket）概念套接字（socket）是通信的基石，是支持TCP/IP协议的网络通信的基本操作单元。它是网络通信过程中端点的抽象表示，包含进行网络通信必须的五种信息：连接使用的协议，本地主机的IP地址，本地进程的协议端口，远地主机的IP地址，远地进程的协议端口。应用层通过传输层进行数据通信时，TCP会遇到同时为多个应用程序进程提供并发服务的问题。多个TCP连接或多个应用程序进程可能需要通过同一个 TCP协议端口传输数据。为了区别不同的应用程序进程和连接，许多计算机操作系统为应用程序与TCP／IP协议交互提供了套接字(Socket)接口。应用层可以和传输层通过Socket接口，区分来自不同应用程序进程或网络连接的通信，实现数据传输的并发服务。建立socket连接建立Socket连接至少需要一对套接字，其中一个运行于客户端，称为ClientSocket ，另一个运行于服务器端，称为ServerSocket 。套接字之间的连接过程分为三个步骤：服务器监听，客户端请求，连接确认。 服务器监听：服务器端套接字并不定位具体的客户端套接字，而是处于等待连接的状态，实时监控网络状态，等待客户端的连接请求。 客户端请求：指客户端的套接字提出连接请求，要连接的目标是服务器端的套接字。为此，客户端的套接字必须首先描述它要连接的服务器的套接字，指出服务器端套接字的地址和端口号，然后就向服务器端套接字提出连接请求。 连接确认：当服务器端套接字监听到或者说接收到客户端套接字的连接请求时，就响应客户端套接字的请求，建立一个新的线程，把服务器端套接字的描述发给客户端，一旦客户端确认了此描述，双方就正式建立连接。而服务器端套接字继续处于监听状态，继续接收其他客户端套接字的连接请求。SOCKET连接与TCP/IP连接创建Socket连接时，可以指定使用的传输层协议，Socket可以支持不同的传输层协议（TCP或UDP），当使用TCP协议进行连接时，该Socket连接就是一个TCP连接。socket则是对TCP/IP协议的封装和应用（程序员层面上）。也可以说，TPC/IP协议是传输层协议，主要解决数据 如何在网络中传输，而HTTP是应用层协议，主要解决如何包装数据。关于TCP/IP和HTTP协议的关系，网络有一段比较容易理解的介绍： “我们在传输数据时，可以只使用（传输层）TCP/IP协议，但是那样的话，如 果没有应用层，便无法识别数据内容，如果想要使传输的数据有意义，则必须使用到应用层协议，应用层协议有很多，比如HTTP、FTP、TELNET等，也 可以自己定义应用层协议。WEB使用HTTP协议作应用层协议，以封装HTTP文本信息，然后使用TCP/IP做传输层协议将它发到网络上。” 我们平时说的最多的socket是什么呢，实际上socket是对TCP/IP协议的封装，Socket本身并不是协议，而是一个调用接口（API），通过Socket，我们才能使用TCP/IP协议。 实际上，Socket跟TCP/IP协议没有必然的联系。Socket编程接口在设计的时候，就希望也能适应其他的网络协议。所以说，Socket的出现 只是使得程序员更方便地使用TCP/IP协议栈而已，是对TCP/IP协议的抽象，从而形成了我们知道的一些最基本的函数接口，比如create、 listen、connect、accept、send、read和write等等。网络有一段关于socket和TCP/IP协议关系的说法比较容易理解：“TCP/IP只是一个协议栈，就像操作系统的运行机制一样，必须要具体实现，同时还要提供对外的操作接口。这个就像操作系统会提供标准的编程接口，比如win32编程接口一样，TCP/IP也要提供可供程序员做网络开发所用的接口，这就是Socket编程接口。”实际上，传输层的TCP是基于网络层的IP协议的，而应用层的HTTP协议又是基于传输层的TCP协议的，而Socket本身不算是协议，就像上面所说，它只是提供了一个针对TCP或者UDP编程的接口。socket是对端口通信开发的工具,它要更底层一些. Socket连接与HTTP连接由于通常情况下Socket连接就是TCP连接，因此Socket连接一旦建立，通信双方即可开始相互发送数据内容，直到双方连接断开。但在实际网络应用中，客户端到服务器之间的通信往往需要穿越多个中间节点，例如路由器、网关、防火墙等，大部分防火墙默认会关闭长时间处于非活跃状态的连接而导致 Socket 连接断连，因此需要通过轮询告诉网络，该连接处于活跃状态。 而HTTP连接使用的是“请求—响应”的方式，不仅在请求时需要先建立连接，而且需要客户端向服务器发出请求后，服务器端才能回复数据。很多情况下，需要服务器端主动向客户端推送数据，保持客户端与服务器数据的实时与同步。此时若双方建立的是Socket连接，服务器就可以直接将数据传送给客户端；若双方建立的是HTTP连接，则服务器需要等到客户端发送一次请求后才能将数据传回给客户端，因此，客户端定时向服务器端发送连接请求，不仅可以保持在线，同时也是在“询问”服务器是否有新的数据，如果有就将数据传给客户端。http协议是应用层的协义 有个比较形象的描述：HTTP是轿车，提供了封装或者显示数据的具体形式；Socket是发动机，提供了网络通信的能力。参考： https://baike.baidu.com/item/socket/281150https://www.2cto.com/net/201211/166537.htmlhttp://jingyan.baidu.com/article/08b6a591e07ecc14a80922f1.html]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[存储系统]]></title>
    <url>%2F2017%2F12%2F14%2F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[三层体系结构的特点三层体系结构依次是：Cache、主存、辅存。 cache-主存:在CPU和主存之间增加一级速度快、但容量较小且每位价格较高的高速缓冲存储Cache)。借助于辅助软硬件，它与主存构成一个有机的整体，以弥补主存速度的不足。这个层次的工作主要由硬件实现。 主存-辅存:这个层次的目的是为了弥补主存容量的它是在主存外面增加一个容量更大、每位价格更速度更慢的存储器(称为辅存，一般是硬盘)。它辅助软硬件的作用，构成一个整体。“主存-辅存常被用来实现虚拟存储器，向编程人员提供大量空间。Cache的特点、作用、工作原理 特点是速度快 作用：弥补CPU与主存之间的运行速度的差距。 工作原理：根据数据分布的局部性和时间局部性在CPU和主存之间设置Cache。 虚拟存储器的特点、工作原理、管理方式虚拟存储器指的是“主存-辅存”层次。虚拟存储器的作用：虚拟存储器，Virtual Machine，简称VM，是对主存（DRAM）的一种抽象，是计算机系统中最重要的概念之一。计算机中有各种存储器，而VM的存在，就是为了帮助我们有效地管理这些存储器，减少错误，提供一种简单的数据交互方法。VM，将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存中来回传送数据，而且为每个进程提供了一致的地址空间，并保护这个地址空间不被其它的进程破坏 段式 段式存储是根据程序逻辑，给程序分段。使得每段大小不同。这种虚拟地址划分方法适合程序设计 段式存储的虚拟地址由段号和段内偏移地址组成。段式虚拟存储器到物理地址的映射通过段表实现 段式虚拟存储会造成空页 页式 概念 程序员在比实际主存大得多的逻辑地址空间中编写程序 程序执行时，把当前需要的程序段和数据块掉入主存，其他暂不使用的放在磁盘上 执行指令时，通过硬件将逻辑地址转化为物理地址。虚拟地址高位为虚页号，低位为页内偏移地址 当程序发生数据访问或程序访问失效(缺页时)，由操作系统把信息从磁盘调入主存中 分页 基本思想：内存被分成固定长度且长度较小的存储块（页框，实页，物理页），每个进程也被划分为固定长度的程序块（页，虚页，逻辑页），通过页表，实现逻辑地址想物理地址转化 逻辑地址：程序中指令所使用的地址（进程所在地址空间） 物理地址：存放指令或数据的实际内存地址 页表结构页表的首地址放在基址寄存器。采用基址寻址方式每个页表项前面有一个虚页号：从0开始递增的序号。页表项又分为几个结构：（1）装入位：该页是否在内存中（2）修改位：该也在内存中是否被修改（3）替换控制位：用于clock算法（4）其他（5）实页号（8进制）段页式 段页式虚拟存储，先把程序按照逻辑分成段，再把每段分成固定大小的页。程序对主存的调入调出是按照页面进行的。但他有可以根据段实现共享和保护。 缺点是段页式虚拟地址转换成物理地址需要查询2个表：段表和页表。段表找到相应页表的位置，页表找到想也页的位置。 段页式细腻地址的结构可以为以下形式：程序地址： 用户号(进程pid) | 段号 | 页号 | 页内偏移地址Cache的地址映像直接映像j= i mod Cache的块数把主存分成若干区，每区与Cache大小相同。区内分块，主存每个区中块的大小和Cache中块的大小相等，主存中每个区包含的块的个数与Cache中块的个数相等。任意一个主存块只能映像到Cache中唯一指定的块中，即相同块号的位置。主存地址分为三部分：区号、块号和块内地址，Cache地址分为：块号和块内地址。直接映像方式下，数据块只能映像到Cache中唯一指定的位置，故不存在替换算法的问题。它不同于全相连Cache，地址仅需比较一次。特点：地址变换简单、速度快，可直接由主存地址提取出Cache地址。但不灵活，块冲突率较高，Cache空间得不到充分利用。公式：12主存地址位数 ＝ 区号 + 区内分块号 + 块内地址Cache地址位数 ＝ 块号+块内地址 全相联映像计算主存地址的各字段的位数、命中率。主存中任何一个块均可以映像装入到Cache中的任何一个块的位置上。主存地址分为块号和块内地址两部分，Cache地址也分为块号和块内地址。Cache的块内地址部分直接取自主存地址的块内地址段。主存块号和Cache块号不相同，Cache块号根据主存块号从块表中查找。Cache保存的各数据块互不相关，Cache必须对每个块和块自身的地址加以存储。当请求数据时，Cache控制器要把请求地址同所有的地址加以比较，进行确认。特点：灵活，块冲突率低，只有在Cache中的块全部装满后才会出现冲突，Cache利用率高。但地址变换机构复杂，地址变换速度慢，成本高。公式：12主存地址位数 ＝ 块号 + 块内地址Cache地址位数＝块号 + 块内地址。 组相联映像j=(i mod Cache的组数)×Cache每组块数+k组相连映像是前两种方式的折衷。主存按Cache容量分区，每个区分为若干组，每组包含若干块。Cache也进行同样的分组和分块。主存中一个组内的块数与Cache中一个组内的块数相等。组间采用直接方式，组内采用全相连方式。组的容量＝1时，即直接映像，组的容量＝整个Cache的容量时，即全相连映像。Cache的存在对于程序员透明，Cache的地址变换和数据块的替换算法都采用硬件实现。公式：12主存地址位数 ＝ 区号 + 组号 + 主存块号 + 块内地址Cache地址位数 ＝ 组号 + 组内块号 + 块内地址 替换策略（FIFO和LRU）略 设置了Cache与未设置Cache时计算机运行速度的计算、内存平均存取时间的计算。平均存取时间=htc+(1–h) (tm) 辅助存储器的性能参数的计算]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
      <tags>
        <tag>计算机组成原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中央处理器]]></title>
    <url>%2F2017%2F12%2F14%2F%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8%2F</url>
    <content type="text"><![CDATA[基本概念程序计数器PC即指令地址寄存器。用来存放当前正在执行的指令地址，或将要执行的下一条指令地址。指令寄存器IR用来存放当前正在执行的指令，以便在指令执行过程中控制完成一条指令的全部功能。指令译码器对指令寄存器IR中的操作码进行分析解释，产生相应的控制信号。MAR、MDR、标志寄存器地址寄存器，数据寄存器。标志寄存器包含CNVZ四个标志位。时钟周期、指令周期、机器周期 时钟周期：是计算机中最基本的、最小的时间单位。在一个时钟周期内,CPU仅完成一个最基本的动作。 机器周期：在计算机中,为了便于管理,常把一条指令的执行过程划分为若干个阶段,每一阶段完成一项工作。例如,取指令、存储器读、存储器写等,这每一项工作称为一个基本操作。完成一个基本操作所需要的时间称为机器周期。 指令周期：执行一条指令所需要的时间,一般由若干个机器周期组成。指令不同,所需的机器周期也不同。 对于一些简单的的单字节指令,在取指令周期中,指令取出到指令寄存器后,立即译码执行,不再需要其它的机器周期。对于一些比较复杂的指令,例如转移指令、乘法指令,则需要两个或者两个以上的机器周期。 通常含一个机器周期的指令称为单周期指令,包含两个机器周期的指令称为双周期指令。 控制存储器为程序一般存放在专用的存储器中，该存储器主要存放控制命令（信号）和下一条执行的微指令地址（下址）。执行一条微指令就是执行一段存放在控制存储器中的微程序。 控制器产生控制信号有两种方法：微程序控制、硬布线控制（组合逻辑控制）略 计算机取指和取操作数的过程及数据通路略 用微程序设计方案设计微指令微指令控制字段的方法： 直接控制法 字段直接编译法 字段间接编译法指令流水的概念、影响流水线性能的因素及解决方法 为提高CPU利用率，加快执行速度，将指令分为若干个阶段，可并行执行不同指令的不同阶段，从而多个指令可以同时执行。在有效地控制了流水线阻塞的情况下，流水线可大大提高指令执行速度。经典的五级流水线：取址、译码/读寄存器、执行/计算有效地址、访问内存（读或写）、结果写回寄存器。 流水线阻塞的情况有三种： 1. 结构相关：指令重叠执行的过程中，硬件资源满足不了指令重叠执行的要求，发生资源冲突，这时将产生结构相关。解决的办法是增加硬件资源。 2. 数据相关：当一条指令需要前面某条指令的执行结果，而两者正在并行执行的情况下，将产生数据相关。解决方式：数据重定向，或称为旁路技术。 3. 控制相关：有跳转语句、分支指令，或其他改变IP值的指令，将产生控制相关。解决方法：分支预测技术，投机执行，延迟分支。]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
      <tags>
        <tag>计算机组成原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[指令系统]]></title>
    <url>%2F2017%2F12%2F14%2F%E6%8C%87%E4%BB%A4%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[指令操作码、地址码的设计方法略 常用的寻址方式及其特点直接寻址、寄存器寻址、基址寻址、变址寻址、间接寻址（寄存器间址、存储器间址）、相对寻址、立即数寻址。参考：图解寻址方式 基本概念：堆栈、标志位、指令字长 标志位：C（产生进位或借位）、V（结果溢出）、Z（结果为0）、N（结果为负） 指令字长分为单字长指令和双字长指令。 执行一条指令的过程 CPU与主存连接示意图 取指令 ：PC -&gt; MAR -&gt; M -&gt; IR -&gt; 微操作信号发生器 执行指令 ：IR -&gt; MAR -&gt; M -&gt; MDR ….（后续执行过程依照不同指令而不同）]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
      <tags>
        <tag>计算机组成原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[主存储器]]></title>
    <url>%2F2017%2F12%2F14%2F%E4%B8%BB%E5%AD%98%E5%82%A8%E5%99%A8%2F</url>
    <content type="text"><![CDATA[RAM和ROM的特性 RAM：通过指令可以随机的个别的对各个存储但愿进行访问读写的存储器，访问时间与存储单元的地址无关。停电会造成信息丢失，具有易失性。 ROM：只能读不能写的存储器，具有非易失性。（ROM不是外部存储器例如硬盘等） Note主存包括RAM和ROM，CPU通过不同的编址方式区别它们。 SRAM、DRAM 两者都是RAM类型的存储器。 DRAM容量大，价格便宜，功率小，常用做主存储器的主要元件。 SRAM速度快，一般用作容量不大的高速存储器（例如高速缓冲存储器Cache）。 存储器容量的扩展 字扩展 位扩展 字位扩展]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
      <tags>
        <tag>计算机组成原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机运算方法和运算部件]]></title>
    <url>%2F2017%2F12%2F14%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%BF%90%E7%AE%97%E6%96%B9%E6%B3%95%E5%92%8C%E8%BF%90%E7%AE%97%E9%83%A8%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[十进制数、二进制数、十六进制数的相互转换 整数十进制转二进制有模2取余法。 小数转二进制有乘2取整法。 二进制转十六进制：二进制从低位到高位四个为一组（高位不够补0），转换为十六进制。反之为十六进制转换二进制。 十进制转十六进制：第一种先把十六进制转换为二进制，再把二进制转换为十六进制。第二种模16取余法，十六进制即为倒序的余数。 机器数的表示方法：原码、补码、反码、移码 原码：用0、1取代符号位。0表示正数，1表示负数。与真值最接近的表示形式。 补码：机器数的最高位为符号位。0表示正数，1表示负数。正数的补码是本身，负数的补码是取反再加1，0的补码是0。 反码：符号位不变各位取反。 移码：符号位取反的补码。用来表示浮点数的阶码。 Note 0表示形式唯一的是补码和移码 补码左移补0，右移补1 补码加减法运算时采用双符号位运算，若双符号位为00或者11则不溢出，反之溢出。 浮点数表示方法$$N=MR^E$$| 尾数符号位（Ms） | 阶码（E） | 尾数（M） || :————–: | :——-: | :——-: | Ms为尾数的符号位，设置在最高位。 E为阶码，一般为整数，其中有一位符号位，设置在E的最高位，用来表示正阶或负阶。 M为尾数，为了保证数据精度，尾数通常用规格化（尾数最高位不能为0）表示：当R=2且尾数值不为0时，其绝对值应大于或等于$(0.5)_{10}$。对于非规格化的浮点数通过将尾数左移或右移并修改阶码值使之满足规格化要求。 奇偶校验码奇校验：将机器数凑成奇数个1偶校验：将机器数凑成偶数个 数据：1230 0 0 0 0 1 1 1 0 奇校验1231 0 0 0 0 0 0 1 1 1 1 0 偶校验1230 0 0 0 1 0 0 1 0 1 1 0 补码一位乘：布斯公式法Note： 乘数最后一位补0。 $Y_{i+1}-Yi=0(Y{i+1}Y_i=00$或$11)$，部分积加1,右移一位。 $Y_{i+1}-Yi=1(Y{i+1}Y_i=10)$，部分积加[X]的补码，右移一位。 $Y_{i+1}-Yi=1(Y{i+1}Y_i=01)$，部分积加[-X]的补码，右移一位。 最后一步$(i=n+1)$不移位。 累加n+1次（n为X和Y的小数位数），右移n次。 原码一位除：加减交替法定点除法运算有 恢复余数法 和 加减交替法 ，在计算机中最常使用的是加减交替法，因为它的操作步数少，而且也不复杂。 当求得的余数为负时，加上除数。 当求得的余数为正时，减去除数。 对定点小数除法要保证除数和被除数的绝对值小于1。 商的符号为两数字符号的异或。 浮点数的加减运算（分五个步骤） 对阶 尾数加减 规格化 舍入 判溢出 得到结果 定点原码数、定点补码数的表示范围机器字长8位包含一位符号位定点原码表示范围为$[-2^{7}+1, 2^7-1]$定点补码表示范围为$[]$]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
      <tags>
        <tag>计算机组成原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机组成原理系统概论]]></title>
    <url>%2F2017%2F12%2F14%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[冯•诺依曼结构计算机的特点 计算机由运算器、控制器、存储器、输入设备、输出设备组成。 采用存储程序的方式，程序和数据放在同一个存储器中，并以二进制表示。 指令由操作码和地址码组成。 指令在存储器中按执行顺序排放，由指令计数器（即程序计数器PC）指明要执行的指令所在存储单元地址。 机器以运算器为中心，输入输出设备与存储器之间的数据传送都通过运算器。 计算机硬件系统的组成计算机由运算器、控制器、存储器、输入设备、输出设备组成。 运算器是对数据进行处理的运算部件，一般进行算数运算和逻辑运算。 控制器实现程序的自动执行。 存储器用来存放程序和数据。 输入设备用来输入原始数据和处理这些数据的程序。 输出设备用来输出计算机的处理结果。 计算机语言：机器语言、汇编语言、高级语言，三种语言的特点 机器语言是用二进制代码表示的计算机能直接识别和执行的一种机器指令的集合。 汇编语言是一种用助记符表示的仍然面向机器的计算机语言。 高级语言是与自然语言相近并为计算机所接受和执行的计算机语言。 计算机系统的构成：硬件系统和软件系统Note 常用三级时序系统：指令周期-机器周期-时钟周期]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
      <tags>
        <tag>计算机组成原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图解寻址方式]]></title>
    <url>%2F2017%2F11%2F21%2F%E5%9B%BE%E8%A7%A3%E5%AF%BB%E5%9D%80%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[直接寻址 直接寻址 间接寻址 存储器间接寻址 寄存器间接寻址 基址寻址 基址寻址 变址寻址 变址寻址 立即数寻址 立即数寻址 寄存器寻址 寄存器寻址 相对寻址 相对寻址]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
      <tags>
        <tag>计算机组成原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据查询]]></title>
    <url>%2F2017%2F11%2F19%2F%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[数据查询功能查询功能是SQL按的核心功能，是数据库用的最多的操作，查询语句是SQL语句比较复杂的语句。以下查询用到的三张表如下所示：Student表： Sno Sname Ssex Sage Sdept 150752 孙兰昌 男 20 计算机系 150765 梁诗笛 女 19 计算机系 … … … … … Course表： Cno Cname Credit Semester c01 高等数学 5 1 c02 数据结构 3 2 … … … … SC表： Sno Cno Grade 150752 c01 90 150765 c02 88 … … … 查询语句的基本结构查询语句的基本结构可描述为：123456select &lt;目标列名序列&gt; --需要哪些列 from &lt;数据源&gt; --来自哪些表 [where &lt;检索条件表达式&gt;] --根据什么条件 [group by &lt;分组依据列&gt;] [having &lt;组提取条件&gt;] [order by &lt;排序依旧列&gt;] 单表查询distinct去重SQL语言中的distinct关键字可以去掉查询结果的重复行，distinct放在select的后边、目标列名的前边。例如：select distinct Sno from SC [not] in、_%[]匹配、escape转义、order by排序 in确定集合in确定某个集合，not in不在某个集合，例如： select Sname, Ssex from Student where Sdept in (&#39;计算机系&#39;, &#39;数学系&#39;)此查询等价于 select Sname, Ssex from Student where Sdept=&#39;计算机系&#39; or Sdept=&#39;数学系&#39; select Sname, Ssex from Student where Sdept not in (&#39;计算机系&#39;, &#39;数学系&#39;)此查询等价于 select Sname, Ssex from Student where Sdept!=&#39;计算机系&#39; and Sdept!=&#39;数学系&#39; 字符串匹配一般形式为：列名 [not] like &lt;匹配串&gt; _：匹配任意一个字符 %：匹配0个或多个字符 []：匹配[]中的任意一个字符。如[aeiou]匹配a、e、i、o、u中的任何一个。对于连续的字母匹配，例如[abcd]可以简写[a-d]。 [^]：不匹配[]中的任何一个字符。如[^abc]表示不匹配a、b、c。对于连续的字母可以简写例如[^a-d]。 escape转义字符匹配语法格式：escape 转义字符例如： where field like &#39;%30\%%&#39; escape &#39;\&#39; 对查询结果进行排序排序语法格式： order by &lt;列名&gt; [asc | desc]asc：升序排序，desc：降序排序。如果指定多个列排序，则按照列的先后顺序排序，即最前面的优先级最高。 使用聚合函数汇总数据 count([distinct] &lt;列名&gt;)：统计本列非空列值个数。 sum() ave() min() max()功能类似 group by分组语法：group by [分组依据列] [having &lt;组约束条件&gt;]SQL先执行where后执行group by再执行having，建议在所有分组之前进行的搜索条件放在where中，分组之后的条件搜索放在having中更为高效。Note：查询年龄小于20学生人数：select Sdept, count(*) from Student where age &lt; 20 group by Sdept，而不能写成：select Sdept, count(*) from Student group by Sdept having Sage &lt; 20，因为在分组之后只保留分组依据列以及聚合函数，因为执行到having时已经没有Sage列了。 多表连接查询内连接使用内连接时，如果两个表的相关字段满足连接条件，则从两个表提取数据并组合成新的记录。语法格式：from table1 [inner] join table on &lt;连接条件&gt;例如：select * from studnet inner join SC on Studnet.Sno = SC.Sno 自连接在自连接时一定要有别名。例如：查询与操作系统学分相同的课程的课程名和学分。select C1.Cname, C2.Credit from Course C1 join Course C2 on C1.Credit = C2.Credit where C2.Cname = &#39;操作系统&#39; 外连接查找不满足条件的记录。left以左表为基础对右表进行筛选，right类似。语法：from table1 left | right [outer] join table2 on &lt;连接条件&gt;例如：查询学生的选课情况，包括选了课程的学生和没有选课程的学生，列出学号、姓名、课程号和成绩。select Studnet.Sno, Sname, Cno, Grade from Student left outer join SC on Student.Sno = SC.Sno 使用TOP限制结果集语法：top n [percent] [with ties]一般与order by同时使用。其中： n为非负整数 top n表示取查询的前n行数据 top n percent：表示取查询结果的前n%行数据 with ties：包括并列的结果例如：查询年龄最大的三个学生的信息,包括并列的情况。select top 3 with ties * from Student order by Sage desc子查询SQL语言中，一个select-from-where语句称为一个查询块。一个查询块嵌入了另外一个select、insert、update或delete则称为子查询或内层查询。 集合测试语法：where 表达式 [not] in (子查询)例如： 查询与小明同在一个系学习的学生。select * from Student where Sdept in (select Sdept from Student where Sname=&#39;小明&#39;) 查询选了c02课程的学生。select * from Student where Sno in (select Sno from SC where Cno=&#39;c02&#39;) and，此查询也可以用多表连接查询实现：select * from Student as S join SC on S.Sno==SC.Sno where Sdept=&#39;计算机系&#39; and Cno=&#39;c02&#39; 比较测试语法：where 表达式 比较运算符 (子查询)其中比较运算符有：= &lt;&gt; &lt; &gt; &lt;= &gt;=。例如： 查询考试成绩高于平均成绩的学生：select * from student from SC group by Sno having AVG(Grade) &gt; (select AVG(Grade) from SC)。 集合测试和比较测试都是先执行子查询，在执行外层查询，子查询只执行一次且不依赖于外层查询，这样的查询称为不相关子查询或嵌套子查询。 存在测试语法：where [not] exists (子查询) 存在测试先执行外层查询，后执行子查询；子层查询的次数由外层查询结果决定。 存在测试只返回真值或假值，所以在子查询中指定列名没有意义，通常用select *代替。例如：查询选修了c01课程的学生：select * from Student where exists (select * from SC where Sno = Student.Sno and Cno = &#39;c01&#39;)]]></content>
      <categories>
        <category>数据库原理与应用</category>
      </categories>
      <tags>
        <tag>数据库原理与应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[寻址方式之——相对寻址、堆栈寻址]]></title>
    <url>%2F2017%2F11%2F18%2F%E5%AF%BB%E5%9D%80%E6%96%B9%E5%BC%8F%E4%B9%8B%E2%80%94%E2%80%94%E7%9B%B8%E5%AF%B9%E5%AF%BB%E5%9D%80%E3%80%81%E5%A0%86%E6%A0%88%E5%AF%BB%E5%9D%80%2F</url>
    <content type="text"><![CDATA[相对寻址 与基址变址寻址方式相类似，相对寻址以程序计数器PC的当前值（R15中的值）为基地址，指令中的地址标号作为偏移量，将两者相加后得到操作数的有效地址。 相对寻址主要用于转移指令，执行本条命令后，转移到（PC）+ Disp，（PC）为程序计数器的内容。 特点： 转移地址不是固定的，它随着PC值的变化而变化，并且总是与PC相差一个固定的值disp，因此无论程序转入存储器的任何地方，均能正确运行，对浮动程序很适用。 位移量可正、可负，通常用补码表示。堆栈寻址堆栈是一种数据结构，按先进后出（First In Last Out，FILO）的方式工作，使用堆栈指针（Stack Pointer, SP）指示当前的操作位置，堆栈指针总是指向栈顶。根据堆栈的生成方式不同，可以把堆栈分为递增堆栈和递减堆栈两种类型。 递增堆栈：向堆栈写入数据时，堆栈由低地址向高地址生长。 递减堆栈：向堆栈写入数据时，堆栈由高地址向低地址生长。同时，根据堆栈指针（SP）指向的位置，又可以把堆栈分为满堆栈（Full Stack）和空堆栈（Empty Stack）两种类型。 满堆栈（Full Stack）：堆栈指针指向最后压入堆栈的数据。满堆栈在向堆栈存放数据时的操作是先移动SP指针，然后存放数据。在从堆栈取数据时，先取出数据，随后移动SP指针。这样保证了SP一直指向有效的数据。 空堆栈（Empty Stack）：堆栈指针SP指向下一个将要放入数据的空位置。空堆栈在向堆栈存放数据时的操作是先放数据，然后移动SP指针。在从堆栈取数据时，是先移动指针，再取数据。这种操作方式保证了堆栈指针一直指向一个空地址（没有有效数据的地址）。]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
      <tags>
        <tag>计算机组成原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[寻址方式之——基址寻址、变址寻址]]></title>
    <url>%2F2017%2F11%2F17%2F%E5%AF%BB%E5%9D%80%E6%96%B9%E5%BC%8F%E4%B9%8B%E2%80%94%E2%80%94%E5%9F%BA%E5%9D%80%E5%AF%BB%E5%9D%80%E3%80%81%E5%8F%98%E5%9D%80%E5%AF%BB%E5%9D%80%2F</url>
    <content type="text"><![CDATA[基址寻址 在计算机设置一个专用的基址寄存器，或者由指令指定一个通用寄存器为基址寄存器。操作数的地址由基址寄存器的内容和指令的地址码A相加得到，这种情况下地址码A常被成为位移量（disp）。 当存储器容量比较大，有指令的地址码部分直接给出的地址不能直接访问到存储器的单元时，通常将存储器分成若干段，段的首地址存放在基址寄存器中，段内的位移量由指令给出。存储器的实际地址就等于基址寄存器和段内位移量相加。 基址寻址主要用来解决程序在存储器中的定位和扩大寻址空间等问题。通常基址寄存器只能由系统程序设定，由特权指令执行，一般用户不能够修改，保证了系统的安全性。变址寻址指令地址码给出地址A和指定的变址寄存器R,将A和R的内容相加就是操作数的地址。常利用变址操作与循环执行程序的方法对数组进行运算。区别 基址寻址主要用于为程序或数据分配存储空间，故基址寄存器的内容通常由操作系统或管理程序确定，在程序运行过程中，值是不可变的，而指令字中的地址码是可变的。 变址寻址中，变址寄存器的内容是用户自己设定的，在程序运行过程中是可变的，而指令字中的地址码是不可变的。编制寻址主要用于处理数组等问题，并且特别适合编制循环程序。]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
      <tags>
        <tag>计算机组成原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[寻址方式之——直接寻址、间接寻址]]></title>
    <url>%2F2017%2F11%2F17%2F%E5%AF%BB%E5%9D%80%E6%96%B9%E5%BC%8F%E4%B9%8B%E2%80%94%E2%80%94%E7%9B%B4%E6%8E%A5%E5%AF%BB%E5%9D%80%E3%80%81%E9%97%B4%E6%8E%A5%E5%AF%BB%E5%9D%80%2F</url>
    <content type="text"><![CDATA[直接寻址指令的地址码部分给出操作数在存储器中的地址，比如给出一个操作数的字段为3位，则寻址方式为有8种。如下图注意：立即寻址方式和直接寻址方式的书写格式的不同，直接寻址的地址要写在括号“[”，“]”内。在程序中，直接地址通常用内存变量名来表示，如：MOV BX, VARW，其中，VARW是内存字变量。试比较下列指令中源操作数的寻址方式(VARW是内存字变量)：12MOV AX, 1234H; MOV AX, [1234H] ;前者是立即寻址，后者是直接寻址MOV AX, VARW; MOV AX, [VARW] ;两者是等效的，均为直接寻址 间接寻址在寻址是，有时根据指令的地址码所取出的内容既不是操作数，也不是下一条要执行的指令，而是操作数的地址或指令的地址，这种方式成为间接寻址。根据地址码指的是寄存器地址还是存储器地址，间接寻址又可以分为寄存器间接寻址和存储器间接寻址两种方式。间接寻址有一次间接寻址和间接寻址两种情况，大多数计算机只允许一次间接寻址。对于存储器一次间接寻址情况，许访问两次存储器才能取得数据，第一次从存储器读出操作数地址，第二次读出操作数。如下图所示 寄存器间接寻址]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
      <tags>
        <tag>计算机组成原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IP地址、IP子网、CIDR]]></title>
    <url>%2F2017%2F11%2F14%2FIP%E5%9C%B0%E5%9D%80%E3%80%81IP%E5%AD%90%E7%BD%91%E3%80%81CIDR%2F</url>
    <content type="text"><![CDATA[标准分类的IP地址先来一张图便于查阅，如下图：在互联网络中，需要为每个主机和路由器等设备分配一个在全世界范围内唯一的IP地址，格式为{&lt;网络号&gt;，&lt;主机号&gt;}IP地址的编址方法共经历了以下五个阶段： 分类的IP地址。 划分子网。 构成超网。 网络地址转换。 IPv6。如下图所示： IP子网的划分格式为：{&lt;网络号&gt;，&lt;子网号&gt;，&lt;主机号&gt;} A类地址的默认子网掩码：255.0.0.0 B类地址的默认子网掩码：255.255.0.0 C类地址的默认子网掩码：255.255.255.0例如一个B类IP为202.194.0.0均分给6个部门使用，求子网掩码、网络号、子网号、主机号？ 从202.194.0.0这个地址可以知道（网络号是202.194，则主机号是16位） 因为2的3次方为8，所以需要从主机号借3位作子网号才能保证分出6子网，剩下的13位作为主机号，每个子网可容纳最大主机数213 - 2 = 8190个，减去网络地址和广播地址。 子网号和主机号 12345678202.194.0.0（子网号000）202.194.0.1~202.194.0.254（主机号）202.194.0.255（广播地址）202.194.32.0（子网号001）202.194.32.1~202.194.32.254（主机号）202.194.32.255（广播地址）202.194.64.0（子网号010）202.194.64.1~202.194.64.254（主机号）202.194.64.255（广播地址）202.194.96.0（子网号011）202.194.96.1~202.194.96.254（主机号）202.194.96.255（广播地址）202.194.128.0（子网号100）202.194.128.1~202.194.128.254（主机号）202.194.128.255（广播地址）202.194.160.0（子网号101）202.194.160.1~202.194.160.254（主机号）202.194.160.255（广播地址）202.194.192.0（子网号110）202.194.192.1~202.194.192.254（主机号）202.194.192.255（广播地址）202.194.224.0（子网号111）202.194.224.1~202.194.224.254（主机号）202.194.224.255（广播地址） 主机号借了3位，子网掩码为11111111.11111111.11100000.00000000即255.255.224.0 3.无分类编址CIDR格式为：{&lt;网络前缀&gt;，&lt;主机号&gt;}CIDR最主要有两个以下特点： 消除传统的A，B，C地址和划分子网的概念，更有效的分配IPv4的地址空间，CIDR使IP地址又回到无分类的两级编码。记法：IP地址：：={&lt;&lt;网络前缀&gt;，&lt;&lt;主机号&gt;}。 CIDR还使用“斜线记法”即在IP地址后面加上“/”然后写网络前缀所占的位数。CIDR把网络前缀都相同的连续IP地址组成一个“CIDR地址块”，即强化路由聚合（构成超网）。例如202.194.20.138/19，此IP中前19位为网络前缀，后13位为主机号。 202.194.20.138/19用二进制表示为：11001010 11000010 00010100 1000101 该地址所在CIDR地址块中最小的地址为11001010 11000010 00000000 00000000，即202.194.0.0 该地址所在CIDR地址块中最大的地址为：11001010 11000010 00011111 11111111，即202.194.31.255 该地址块中共有213=8192个地址 /19对应的子网掩码为11111111.11111111.11100000.00000000，即255.255.224.0]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[寻址方式之——立即数寻址、寄存器寻址]]></title>
    <url>%2F2017%2F11%2F14%2F%E5%AF%BB%E5%9D%80%E6%96%B9%E5%BC%8F%E2%80%94%E2%80%94%E7%AB%8B%E5%8D%B3%E6%95%B0%E5%AF%BB%E5%9D%80%E3%80%81%E5%AF%84%E5%AD%98%E5%99%A8%E5%AF%BB%E5%9D%80%2F</url>
    <content type="text"><![CDATA[立即数寻址所需的操作数由指令直接给出，就称为立即数（或直接数）寻址方式。这种方式的特点是：取指令时，操作码和操作数同时被取出，减少了访存次数，提高了指令的执行速度。但是由于这一操作数是指令的一部分，不能修改，所以这种方式只能适用操作数固定的情况，并且操作数的位数有限。通常用于给某一寄存器单元赋初值或者提供一个常数，例如C语言里int a = 1，运用到了立即数寻址。立即数可以是8位、16位或32位，该数值紧跟在操作码之后。如果立即数为16位或32位，那么，它将按“高高低低”的原则进行存储。例如：123MOV AH, 80HADD AX, 1234HMOV ECX, 123456H 以上指令中的第二操作数都是立即数，在汇编语言中规定：立即数不能作为指令中的第一操作数，该规定与高级语言中“赋值语句的左边不能是常量”的规定相一致。立即数寻址方式通常用于对通用寄存器或内存单元赋初值。图是指令”MOV AX, 4576H”存储形式和执行示意图。将4576H数据送入AX通用寄存器，类似于赋值语句。 寄存器寻址计算机的中央处理器一般设置有一定数量的通用寄存器，用来存放操作数，操作数的地址或中间结果。假如指令地址码部分给出某一通用寄存器地址即给出地址码A，而且所需的操作数就在这一寄存器中，则称为寄存器寻址。通用寄存器数量一般在几个到几十个之间，例如x86架构CPU有4个数据寄存器(EAX、EBX、ECX和EDX)，MIPS架构CPU有32个通用寄存器（$0-$31），ARM架构CPU有16个32位的寄存器（r0-r15）。从寄存器中存取数据比从存储器中存取数据快得多，所以这种寻址方式可以缩短指令长度，节省存储空间，提高指令的执行速度。 速度的比较按照离CPU由近到远的顺序依次是CPU寄存器、Cache、内存、硬盘，越靠近CPU的存储器容量越小但访问速度越快，下图给出了各种存储器的容量和访问速度的典型值。参考： http://blog.csdn.net/zlzlei/article/details/7790363http://blog.csdn.net/huangxb_csu/article/details/5976561http://blog.csdn.net/gujing001/article/details/8476685http://www.cnblogs.com/onroad/archive/2009/07/13/1522673.html]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
      <tags>
        <tag>计算机组成原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu使用蓝灯无限流量]]></title>
    <url>%2F2017%2F11%2F03%2FUbuntu%E4%BD%BF%E7%94%A8%E8%93%9D%E7%81%AF%E6%97%A0%E9%99%90%E6%B5%81%E9%87%8F%2F</url>
    <content type="text"><![CDATA[lantern因为蓝灯3是通过用户的 MAC 地址来判断用户是否使用完免费高速流量。这里修改 MAC 地址的具体步骤如下： 通过 ifconfig 查看网卡设备，这里是enp2s0，有些地方是 eth0，以下统称 net_card 。 关闭网卡设备 sudo /sbin/ifconfig net_card down 修改 MAC 地址 sudo /sbin/ifconfig net_card hw ether 00:AA:BB:CC:DD:EE (要修改的MAC地址) 重新启用网卡 sudo /sbin/ifconfig net_card up 这是临时性修改MAC地址的方法，系统重启之后就会失效。不过这也比较符合我们的需求，一个MAC地址的免费高速流量用完之后就换另一个地址。]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>Other</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[校园网自动登录脚本]]></title>
    <url>%2F2017%2F10%2F31%2F%E6%A0%A1%E5%9B%AD%E7%BD%91%E8%87%AA%E5%8A%A8%E7%99%BB%E5%BD%95%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[校园网自动登录脚本环境 python 2.7或python 3.5均可用，脚本外部依赖requests库，请在运行脚本前pip3或者pip安装requests。 python 2.7运行时务必加上下面一行代码，指定编码为utf8，python3可以忽略。 具体实现 指定编码方式为utf8。 12# coding: utf-8import requests 通过Chrome浏览器得知校园网登录地址，注意直接在浏览器输入的地址不一定是发送数据的地址，我学校是下面这个。 1url = 'http://210.31.32.126/cgi-bin/do_login' 浏览器头信息用来伪装浏览器 123456789101112131415161718def login(): postdata = &#123;'username': '你的校园网账号', 'password': '&#123;TEXT&#125;你的密码', 'drop': '0', 'type': '1', 'n': '100'&#125; headers = &#123;'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Accept-Language': 'zh-CN,zh;q=0.8', 'Connection': 'keep-alive', 'Content-Length': '65', 'Content-Type': 'application/x-www-form-urlencoded', 'Cookie': 'PHPSESSID=a70fr8pfvhhtt329qvb21p7ka6', 'Host': '210.31.32.126', 'Origin': 'http://210.31.32.126', 'Referer': 'http://210.31.32.126/', 'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.91 Safari/537.36'&#125; requests.post(url, data=postdata) 查看连接的是否是校园网，以及是否连上网1234567891011121314def is_connect_edu(): status_code = requests.get(url).status_code if status_code == 200: return True else: return Falsedef is_connect_web(): r = requests.get("http://www.baidu.com").text if r.find('210.31.32.126') != -1: return False else: return True 直到校园网连接上为止123456789while True: if is_connect_edu(): # 是否连接上校园网 if not is_connect_web(): # 是否连接上外网 login() if requests.get('http://www.baidu.com').status_code==200: print('Already connected Internet') else: print('Not connected Internet') break Ubuntu开机自动启动登录root权限修改/etc/rc.local文件在exit 0上一行加上python3 xiaoyuanwang.py即可实现开机启动此脚本 获取源码点击获取源码]]></content>
      <categories>
        <category>小程序</category>
      </categories>
      <tags>
        <tag>小程序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[极限的保号性、无穷小运算法则、七种未定型]]></title>
    <url>%2F2017%2F10%2F31%2F%E6%9E%81%E9%99%90%E7%9A%84%E4%BF%9D%E5%8F%B7%E6%80%A7%E3%80%81%E6%97%A0%E7%A9%B7%E5%B0%8F%E8%BF%90%E7%AE%97%E6%B3%95%E5%88%99%E3%80%81%E4%B8%83%E7%A7%8D%E6%9C%AA%E5%AE%9A%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[极限的保号性、运算法则、七种未定型极限的保号性 $\lim\limits_{x\to a}f(x)=A(A\neq0)$则$f(x)$与$A$同号。 $f(x)&gt;0$，$\lim\limits_{x\to a}f(x)=A$则$A\geq0$。无穷小运算 相同的运算法则 $o(x^m)\pm o(x^n)=o(x^n)$其中$(m&gt;n)$ $x^mo(x^n)=o(x^{m+n})$ $\frac{o(x^m)}{o(x^n)}=0$其中$(m&gt;n)$ $ko(x^n)=o(x^n)$ 注意无穷大加减运算与无穷小相反。 $o(x^m)\pm o(x^n)=o(x^m)$其中$(m&gt;n)$ 七种未定型的极限1. 第一类：$\frac{0}{0}$，$\frac{\infty}{\infty}$，$0\cdot\infty$ 洛必达法则 等价无穷小代换 泰勒展开式 消去去穷大（做大题用） 抓大头（做选择、填空或者检验大题答案用）2. 第二类：$\infty^0$，$0^0$，$1^*$(1的任意次幂) $1^*$常用${f(x)}^{g(x)}=e^{(f(x)-1)g(x)}$ $\infty^0$，$0^0$常用${u(x)}^{v(x)}=e^{v(x)\ln u(x)}$3. 第三类：$\infty-\infty$ 有分母时通分化成前两种情况。 没有分母倒代换构造分母。]]></content>
      <categories>
        <category>微积分</category>
      </categories>
      <tags>
        <tag>微积分</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用泰勒、微积分公式]]></title>
    <url>%2F2017%2F10%2F27%2F%E5%B8%B8%E7%94%A8%E6%B3%B0%E5%8B%92%E3%80%81%E5%BE%AE%E7%A7%AF%E5%88%86%E5%85%AC%E5%BC%8F%E3%80%81%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[常用公式常用穷小替换$x=&gt;\sin x=&gt;\tan x=&gt;\arcsin x=&gt;\arctan x=&gt;\ln (x+1)=&gt;e^x-1$$(x+1)^a-1=&gt;ax$$a^x-1=&gt;xln(a)$$1-\cos x=&gt;\frac{1}{2}x^2$$\tan x-\sin x=&gt;\tan x(1-\cos x)=&gt;\frac{1}{2}x^3$ 常用泰勒展开式 $x-f(x)$展开$x-\sin x=\frac{1}{6}x^3+o(x^3)$$x-\arcsin x=-\frac{1}{6}x^3+o(x^3)$$x-\tan x=-\frac{1}{3}x^3+o(x^3)$$x-\arctan x=\frac{1}{3}x^3+o(x^3)$ 三角函数展开$e^x=1+x+\frac{x^2}{2!}+\frac{x^3}{3!}+o(x^3)$$\sin x=x-\frac{x^3}{3!}+\frac{x^5}{5!}+o(x^5)$$\cos x=1-\frac{x^2}{2!}+\frac{x^4}{4!}+o(x^4)$$\ln(x+1)=x-\frac{1}{2}x^2+\frac{1}{3}x^3+o(x^3)$常用微分公式$d\tan x=(\sec x)^2dx$$d\cot x=-(\csc x)^2dx$$d\sec x=\sec x\tan xdx$$d\csc x=-\csc x\cot xdx$$d\arcsin x=\frac{1}{\sqrt{1-x^2}}dx$$d\arccos x=-\frac{1}{\sqrt{1-x^2}}dx$$d\arctan x=\frac{1}{1+x^2}dx$$darcot x=-\frac{1}{1+x^2}dx$ 常用高阶导数公式$(e^{ax})^{(n)}=a^ne^{an}$$(\sin ax)^{(n)}=a^n\sin (ax+n\frac{\Pi}{2})$$(\cos ax)^{(n)}=a^n\cos (ax+n\frac{\Pi}{2})$$(\ln (1+x))^{(n)}=(-1)^{n-1}\frac{(n-1)!}{(x+1)^n}$$(\frac{1}{x})^{(n)}=(-1)^n\frac{n!}{x^{n+1}}$ 莱布尼茨公式$(uv)^{(n)}=u^{(n)}v+C_n^1u^{(n-1)}v+C_n^ku^{(n-k)}v^{(k)}+uv^{n}$ 常用积分公式$\int \tan xdx=-\ln|\cos x|+C$$\int \cot xdx=\ln|\sin x|+C$$\int \sec xdx=\ln\left|\sec x+\tan x\right|+C$$\int \csc x dx=\ln\left|\csc x-\cot x\right|+C$$\int \sec^2(x)dx=\tan x+C$$\int \csc xdx=\cot x+C$$\int \frac{1}{a^2+x^2}dx=\frac{1}{a}\tan(\frac{1}{a}x)+C$$\int \frac{1}{a^2-x^2}dx=\ln\left|\frac{a+x}{a-x}\right|+C$$\int \frac{1}{\sqrt{a^2-x^2}}dx=\arcsin\frac{1}{a}x$$\int \frac{1}{\sqrt{x^2\pm a^2}}dx=\ln|x+\sqrt{x^2\pm a^2}|+C$$\int \ln xdx=x\ln x-x+C$Mathmatica常用命令 Solve[x^2 + a x + 1 == 0, x]求方程的解 Integrate[f,x,x_min,x_max]求定积分和不定积分 Limit[Sin[x]/x, x -&gt; 0]求极限]]></content>
      <categories>
        <category>微积分</category>
      </categories>
      <tags>
        <tag>微积分</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CRC冗余码]]></title>
    <url>%2F2017%2F10%2F26%2FCRC%E5%86%97%E4%BD%99%E7%A0%81%2F</url>
    <content type="text"><![CDATA[CRC校验基本原理CRC检验原理实际上就是在一个p位二进制数据序列之后附加一个r位二进制检验码(序列)，从而构成一个总长为n＝p＋r位的二进制序列；附加在数据序列之后的这个检验码与数据序列的内容之间存在着某种特定的关系。如果因干扰等原因使数据序列中的某一位或某些位发生错误，这种特定关系就会被破坏。因此，通过检查这一关系，就可以实现对数据正确性的检验。 几个基本概念 帧检验序列FCS（Frame Check Sequence）：为了进行差错检验而添加的冗余码。 多项式模2运行：实际上是按位异或(Exclusive OR)运算，即相同为0，相异为1，也就是不考虑进位、借位的二进制加减运算。如：$10011011 + 11001010 = 01010001$。 生成多项式（generator polynomial）：当进行CRC检验时，发送方与接收方需要事先约定一个除数，即生成多项式，一般记作$G(x)$。生成多项式的最高位与最低位必须是1。常用的CRC码的生成多项式有：$CRC8=X^8+X^5+X4+1$$CRC-CCITT=X^16+X^12+X^5+1$$CRC16=X^16+X^15+X^5+1$$CRC12=X^12+X^11+X^3+X^2+1$$CRC32=X^32+X^26+X^23+X^22+X^16+X^12+X^11+X^10+X^8+X^7+X^5+X^4+X^2+X^1+1$每一个生成多项式都可以与一个代码相对应，如CRC8对应代码：100110001。CRC检验码的计算设信息字段为K位，校验字段为R位，则码字长度为$N(N=K+R)$。设双方事先约定了一个R次多项式$g(x)$，则CRC码：$V(x)=A(x)g(x)=xRm(x)+r(x)$其中:$m(x)$为K次信息多项式， $r(x)$为$R-1$次校验多项式。这里$r(x)$对应的代码即为冗余码，加在原信息字段后即形成CRC码。r(x)的计算方法为：在K位信息字段的后面添加R个0，再除以$g(x)$对应的代码序列，得到的余数即为$r(x)$对应的代码(应为R－1位；若不足，而在高位补0)。 计算示例 这里$g(x)=11001$，生成的CRC冗余码为$1010$，最终得到的码字是$1011001010$即码字 = 被除 + 数冗余码。错误检测当接收方收到数据后，用收到的数据对P（事先约定的）进行模2除法，若余数为0，则认为数据传输无差错；若余数不为0，则认为数据传输出现了错误，由于不知道错误发生在什么地方，因而不能进行自动纠正，一般的做法是丢弃接收的数据。 Note CRC是一种常用的检错码，并不能用于自动纠错。 只要经过严格的挑选，并使用位数足够多的除数 P，那么出现检测不到的差错的概率就很小很小。 仅用循环冗余检验 CRC 差错检测技术只能做到无差错接受（只是非常近似的认为是无差错的），并不能保证可靠传输。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用jieba和wordcloud生成词云]]></title>
    <url>%2F2017%2F10%2F26%2F%E5%88%A9%E7%94%A8jieba%E5%92%8Cwordcloud%E7%94%9F%E6%88%90%E8%AF%8D%E4%BA%91%2F</url>
    <content type="text"><![CDATA[利用wordcloud和jieba做一个词云环境使用到的轮子：matplotlib，jieba，scipy，wordcloud，numpy，PIL。python2对jieba的中文分词支持不是很好，所以使用python3。1234567python 3.6.1jieba 0.39matplotlib 1.0.4scipy 1.0.0wordcloud 1.3.1numpy 1.13.3PIL 1.1.6 Github源代码具体实现导入轮子1234567#encoding=utf-8import jiebaimport matplotlib.pyplot as pltfrom scipy.misc import imreadfrom wordcloud import WordCloud, STOPWORDS, ImageColorGeneratorimport numpy as npfrom PIL import Image 所用到的库都能用pip3安装。 生成分词123text_from_file=open('data.txt','r').read()Word_spilt_jieba = jieba.cut(text_from_file,cut_all = False)word_space = ' '.join(Word_spilt_jieba) 数据是从网上复制了几份十九大，国庆，小说的内容，从文本中读入数据到text，用jieba进行分词，不使用全模式，全模式匹配会出现重复关键词的现象，使用后效果并不好。 自定义词云背景12img=imread('bipt.jpg')img = np.array(Image.open('bipt.jpg')) 设置生成词云的背景，这里用到了numpy将图片转换为矩阵，图片需要自己下载定义背景。 生成词云12345678910my_wordcloud = WordCloud( background_color='white', #设置背景颜色 mask=img, #背景图片 max_words = 200, #设置最大显示的词数 stopwords = STOPWORDS, #设置停用词 #设置字体格式，字体格式 .ttf文件需自己网上下载，最好将名字改为英文，中文名路径加载会出现问题。 font_path = 'simkai.ttf', max_font_size = 100, #设置字体最大值 random_state=50, #设置随机生成状态，即多少种配色方案 ).generate(word_space) 设置wordcloud参数，注意这里有一个字体必须自己设置中文字体，否则生成的词云不能出现中文，我用到的是simkai.ttf，下载地址：simkai字体。 显示词云12345iamge_colors = ImageColorGenerator(img)plt.imshow(my_wordcloud)plt.axis('off')plt.show()my_wordcloud.to_file('res.jpg') 取图片的颜色作为词云的颜色，并显示词云。如下图]]></content>
      <categories>
        <category>小程序</category>
      </categories>
      <tags>
        <tag>小程序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬取QQ空间数据进行分析]]></title>
    <url>%2F2017%2F10%2F24%2F%E7%88%AC%E5%8F%96QQ%E7%A9%BA%E9%97%B4%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[主要思路： 通过selenium+phantomjs模拟登录qq空间取到cookies和g_qzonetoken，并算出gtk 通过Requests库利用前面得到的url参数，构造http请求 分析请求得到的响应，是一个json，利用正则表达式提取字段 设计数据表，并将提取到的字段插入到数据库中 通过qq邮箱中的导出联系人功能，把好友的qq号导出到一个csv文件，遍历所有的qq号爬取所有的说说 通过sql查询和ipython分析数据，并将数据可视化 通过python的第三方库jieba、wordcloud基于说说的内容做一个词云 通过selenium+phantomjs模拟登录qq空间取到cookies和g_qzonetoken，并算出gtk具体实现1234567891011121314151617181920212223242526272829303132333435import refrom selenium import webdriverfrom time import sleepfrom PIL import Image#定义登录函数def QR_login(): def getGTK(cookie): """ 根据cookie得到GTK """ hashes = 5381 for letter in cookie['p_skey']: hashes += (hashes &lt;&lt; 5) + ord(letter)return hashes &amp; 0x7fffffff browser=webdriver.PhantomJS(executable_path="D:\phantomjs.exe")#这里要输入你的phantomjs所在的路径 url="https://qzone.qq.com/"#QQ登录网址 browser.get(url) browser.maximize_window()#全屏 sleep(3)#等三秒 browser.get_screenshot_as_file('QR.png')#截屏并保存图片 im = Image.open('QR.png')#打开图片 im.show()#用手机扫二维码登录qq空间 sleep(20)#等二十秒，可根据自己的网速和性能修改 print(browser.title)#打印网页标题 cookie = &#123;&#125;#初始化cookie字典 for elem in browser.get_cookies():#取cookies cookie[elem['name']] = elem['value']print('Get the cookie of QQlogin successfully!(共%d个键值对)' % (len(cookie))) html = browser.page_source#保存网页源码 g_qzonetoken=re.search(r'window\.g_qzonetoken = \(function\(\)\&#123; try\&#123;return (.*?);\&#125; catch\(e\)',html)#从网页源码中提取g_qzonetoken gtk=getGTK(cookie)#通过getGTK函数计算gtk browser.quit()return (cookie,gtk,g_qzonetoken.group(1))if __name__=="__main__": QR_login() 通过火狐浏览器的一个叫json-dataview的插件可以看到这个响应是一个json格式的12345678910111213141516171819202122232425262728293031323334353637383940414243444546def parse_mood(i): '''从返回的json中，提取我们想要的字段''' text = re.sub('"commentlist":.*?"conlist":', '', i)if text: myMood = &#123;&#125; myMood["isTransfered"] = False tid = re.findall('"t1_termtype":.*?"tid":"(.*?)"', text)[0] # 获取说说ID tid = qq + '_' + tid myMood['id'] = tid myMood['pos_y'] = 0 myMood['pos_x'] = 0 mood_cont = re.findall('\],"content":"(.*?)"', text)if re.findall('&#125;,"name":"(.*?)",', text): name = re.findall('&#125;,"name":"(.*?)",', text)[0] myMood['name'] = nameif len(mood_cont) == 2: # 如果长度为2则判断为属于转载 myMood["Mood_cont"] = "评语:" + mood_cont[0] + "---------&gt;转载内容:" + mood_cont[1] # 说说内容 myMood["isTransfered"] = True elif len(mood_cont) == 1: myMood["Mood_cont"] = mood_cont[0]else: myMood["Mood_cont"] = "" if re.findall('"created_time":(\d+)', text): created_time = re.findall('"created_time":(\d+)', text)[0] temp_pubTime = datetime.datetime.fromtimestamp(int(created_time)) temp_pubTime = temp_pubTime.strftime("%Y-%m-%d %H:%M:%S") dt = temp_pubTime.split(' ') time = dt[1] myMood['time'] = time date = dt[0] myMood['date'] = dateif re.findall('"source_name":"(.*?)"', text): source_name = re.findall('"source_name":"(.*?)"', text)[0] # 获取发表的工具（如某手机） myMood['tool'] = source_nameif re.findall('"pos_x":"(.*?)"', text):#获取经纬度坐标 pos_x = re.findall('"pos_x":"(.*?)"', text)[0] pos_y = re.findall('"pos_y":"(.*?)"', text)[0]if pos_x: myMood['pos_x'] = pos_xif pos_y: myMood['pos_y'] = pos_y idname = re.findall('"idname":"(.*?)"', text)[0] myMood['idneme'] = idname cmtnum = re.findall('"cmtnum":(.*?),', text)[0] myMood['cmtnum'] = cmtnumreturn myMood#返回一个字典 我们想要的东西已经提取出来了，接下来需要设计数据表，通过navicat可以很方便的建表，然后通过python连接mysql数据库，写入数据。这是创建数据表的sql代码1234567891011121314CREATE TABLE `mood` (`name` varchar(80) DEFAULT NULL,`date` date DEFAULT NULL,`content` text,`comments_num` int(11) DEFAULT NULL,`time` time DEFAULT NULL,`tool` varchar(255) DEFAULT NULL,`id` varchar(255) NOT NULL,`sitename` varchar(255) DEFAULT NULL,`pox_x` varchar(30) DEFAULT NULL,`pox_y` varchar(30) DEFAULT NULL,`isTransfered` double DEFAULT NULL,PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 其实到这里爬虫的主要的代码就算完了，之后主要是通过QQ邮箱的联系人导出功能，构建url列表，最后等着它运行完成就可以了。这里我单线程爬200多个好友用了大约三个小时，拿到了十万条说说。下面是爬虫的主体代码。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#从csv文件中取qq号，并保存在一个列表中csv_reader = csv.reader(open('qq.csv'))friend=[]for row in csv_reader: friend.append(row[3])friend.pop(0)friends=[]for f in friend: f=f[:-7] friends.append(f)headers=&#123;'Host': 'h5.qzone.qq.com', 'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:53.0) Gecko/20100101 Firefox/53.0', 'Accept': '*/*', 'Accept-Language':'zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3', 'Accept-Encoding': 'gzip, deflate, br', 'Referer': 'https://user.qzone.qq.com/790178228?_t_=0.22746974226377736', 'Connection':'keep-alive'&#125;#伪造浏览器头conn = MySQLdb.connect('localhost', 'root', '123456', 'qq_mood', charset="utf8", use_unicode=True)#连接mysql数据库cursor = conn.cursor()#定义游标cookie,gtk,qzonetoken=QRlogin#通过登录函数取得cookies，gtk，qzonetokens=requests.session()#用requests初始化会话for qq in friends:#遍历qq号列表 for p in range(0,1000): pos=p*20 params=&#123;'uin':qq, 'ftype':'0', 'sort':'0', 'pos':pos, 'num':'20', 'replynum':'100', 'g_tk':gtk, 'callback':'_preloadCallback', 'code_version':'1', 'format':'jsonp', 'need_private_comment':'1', 'qzonetoken':qzonetoken &#125; response=s.request('GET','https://h5.qzone.qq.com/proxy/domain/taotao.qq.com/cgi-bin/emotion_cgi_msglist_v6',params=params,headers=headers,cookies=cookie)print(response.status_code)#通过打印状态码判断是否请求成功 text=response.text#读取响应内容 if not re.search('lbs', text):#通过lbs判断此qq的说说是否爬取完毕 print('%s说说下载完成'% qq)break textlist = re.split('\&#123;"certified"', text)[1:]for i in textlist: myMood=parse_mood(i)'''将提取的字段值插入mysql数据库，通过用异常处理防止个别的小bug中断爬虫，开始的时候可以先不用异常处理判断是否能正常插入数据库''' try: insert_sql = ''' insert into mood(id,content,time,sitename,pox_x,pox_y,tool,comments_num,date,isTransfered,name) VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s) ''' cursor.execute(insert_sql, (myMood['id'],myMood["Mood_cont"],myMood['time'],myMood['idneme'],myMood['pos_x'],myMood['pos_y'],myMood['tool'],myMood['cmtnum'],myMood['date'],myMood["isTransfered"],myMood['name'])) conn.commit()except: passprint('说说全部下载完成！') 数据分析学生QQ用的多还是微信用的多？ 先用sql进行聚合分析，然后通过ipython作图，将数据可视化。统计一年之中每天的说说数目，可以发现每年除夕这一天是大家发说说最多的一天，可以看出2015年9月达到了一个高峰，主要因为数据是2015级的，所以在2015年九月大学入学的，之后开始下降，好多人开始玩微信，逐渐放弃了QQ，所以北石化学生用微信还是多。 通过下面这个年变化图可以更直观的看出QQ使用的频率越来越少，可能因为大学里班级，社团，活动有很多的微信群，越来越少的北石化学生使用QQ。 学生晚上几点睡觉？通过这个每小时段说说发表的数目柱形图，可以发现大家在晚上22点到23点左右是最多的，另外中午十二点到一点也有一个小高峰!由此可见大多数学生在宿舍十一点熄灯后，并不会按时睡觉。 学生的经济情况怎么样？用Excel的内容筛选功能，做了一个手机类型的饼图，通过这个饼图可以看出使用最多的手机是苹果，小米，魅族，华为这四个手机品牌，说明大多数大学生还是比较倾向于性价比比较高的手机，从某一方面可以体现大多数同学还是中等生活水平。 学生都在说些什么？通过将mood表中的content字段导出为txt文本文件，利用python的jieba和wordcloud这两个第三方库，可以生成基于说说内容的词云.看看大家在国庆期间都再说些什么，很明显关于，习近平主席，国庆节，人民英雄纪念碑等关键词明显增多，同样也有计算机，英语，考试等关于学习的字段。 ，]]></content>
      <categories>
        <category>小程序</category>
      </categories>
      <tags>
        <tag>小程序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python写一个简单的神经网络]]></title>
    <url>%2F2017%2F10%2F21%2FPython%E5%86%99%E4%B8%80%E4%B8%AA%E7%AE%80%E7%AD%94%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[简单的神经网络算法，包括基本的后向传播BP算法，前向传播算法，更新权重使用的梯度下降算法，基本的框架算是有了，学习使用。注意输入每一行数据时候在神经网络中会加入bias偏量，神经网络的层数和每层个数为自定义，搞了很久才知道输入矩阵多了一个维度，权重和后向传播更新的delta都是每列神经元之间的关系，关于s形函数暂时用了两种，分别是logistic() 和 tanh() 效果差不多，简单的模型作为笔记学习使用。 获取源码Github源码在这里 具体实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576import numpy as npdef tanh(x): return np.tanh(x)def tanh_deriv(x): return 1.0 - np.tanh(x) * np.tanh(x)def logistic(x): return 1 / (1 + np.exp(-x))def logistic_derivative(x): return logistic(x) * (1 - logistic(x))class NeuralNetwork: def __init__(self, layers, activation='tanh'): if activation == 'logistic': self.activation = logistic self.activation_deriv = logistic_derivative elif activation == 'tanh': self.activation = tanh self.activation_deriv = tanh_deriv self.weights = [] for i in range(1, len(layers) - 1): self.weights.append( (2 * np.random.random((layers[i - 1] + 1, layers[i] + 1)) - 1) * 0.25) self.weights.append( (2 * np.random.random((layers[-2] + 1, layers[-1])) - 1) * 0.25) def fit(self, X, y, learning_rate=0.2, epochs=10000): X = np.atleast_2d(X) temp = np.ones([X.shape[0], X.shape[1] + 1]) temp[:, 0:-1] = X # adding the bias unit to the input layer X = temp y = np.array(y) for k in range(epochs): i = np.random.randint(X.shape[0]) a = [X[i]] for l in range(len(self.weights)): # going forward network, for each layer a.append(self.activation(np.dot(a[l], self.weights[l]))) error = y[i] - a[-1] # Computer the error at the top layer # For output layer, Err calculation (delta is updated error) deltas = [error * self.activation_deriv(a[-1])] # Staring backprobagation for l in range(len(a) - 2, 0, -1): deltas.append(deltas[-1].dot(self.weights[l].T) * self.activation_deriv(a[l])) deltas.reverse() for i in range(len(self.weights)): layer = np.atleast_2d(a[i]) delta = np.atleast_2d(deltas[i]) self.weights[i] += learning_rate * layer.T.dot(delta) def predict(self, x): x = np.array(x) temp = np.ones(x.shape[0] + 1) temp[0:-1] = x a = temp for l in range(0, len(self.weights)): a = self.activation(np.dot(a, self.weights[l])) return ann = NeuralNetwork([2, 2, 3, 1], 'tanh')X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])y = np.array([0, 1, 1, 0])nn.fit(X, y)for i in [[0, 0], [0, 1], [1, 0], [1, 1]]: print(i, nn.predict(i))]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
</search>
